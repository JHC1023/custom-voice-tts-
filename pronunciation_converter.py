"""
ì˜ì–´ë¥¼ í•œê¸€ ë°œìŒìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê°œì„ ëœ ëª¨ë“ˆ
"""
import re


class EnglishToKoreanPronunciation:
    """ì˜ì–´ë¥¼ í•œê¸€ ë°œìŒìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤ (ê°œì„ ëœ ë²„ì „)"""

    def __init__(self):
        # í™•ì¥ëœ ì˜ì–´ ë‹¨ì–´ -> í•œê¸€ ë°œìŒ ì‚¬ì „
        self.word_dict = {
            # ê¸°ë³¸ ì¸ì‚¬ë§
            'hello': 'í—¬ë¡œ', 'hi': 'í•˜ì´', 'hey': 'í—¤ì´', 'bye': 'ë°”ì´', 'goodbye': 'êµ¿ë°”ì´',
            'yes': 'ì˜ˆìŠ¤', 'no': 'ë…¸', 'okay': 'ì˜¤ì¼€ì´', 'ok': 'ì˜¤ì¼€ì´',

            # ê°ì‚¬/ì‚¬ê³¼ í‘œí˜„
            'thank': 'ë•¡í¬', 'thanks': 'ë•¡í¬ìŠ¤', 'you': 'ìœ ', 'welcome': 'ì›°ì»´',
            'please': 'í”Œë¦¬ì¦ˆ', 'sorry': 'ì˜ë¦¬', 'excuse': 'ìµìŠ¤íì¦ˆ', 'me': 'ë¯¸',

            # ì‹œê°„ ê´€ë ¨
            'good': 'êµ¿', 'morning': 'ëª¨ë‹', 'afternoon': 'ì• í”„í„°ëˆˆ', 'evening': 'ì´ë¸Œë‹',
            'night': 'ë‚˜ì´íŠ¸', 'day': 'ë°ì´', 'time': 'íƒ€ì„', 'today': 'íˆ¬ë°ì´',
            'tomorrow': 'íˆ¬ëª¨ë¡œ', 'yesterday': 'ì˜ˆìŠ¤í„°ë°ì´', 'now': 'ë‚˜ìš°', 'later': 'ë ˆì´í„°',
            'early': 'ì–¼ë¦¬', 'late': 'ë ˆì´íŠ¸', 'soon': 'ìˆœ',

            # ì¸ì‚¬ ê´€ë ¨
            'nice': 'ë‚˜ì´ìŠ¤', 'meet': 'ë¯¸íŠ¸', 'to': 'íˆ¬', 'great': 'ê·¸ë ˆì´íŠ¸',
            'wonderful': 'ì›ë”í’€', 'amazing': 'ì–´ë©”ì´ì§•', 'awesome': 'ì–´ì¸',

            # ìˆ«ì (í™•ì¥)
            'zero': 'ì§€ë¡œ', 'one': 'ì›', 'two': 'íˆ¬', 'three': 'ì“°ë¦¬', 'four': 'í¬', 'five': 'íŒŒì´ë¸Œ',
            'six': 'ì‹ìŠ¤', 'seven': 'ì„¸ë¸', 'eight': 'ì—ì´íŠ¸', 'nine': 'ë‚˜ì¸', 'ten': 'í…',
            'eleven': 'ì¼ë ˆë¸', 'twelve': 'íŠ¸ì›°ë¸Œ', 'thirteen': 'ì¨í‹´', 'fourteen': 'í¬í‹´',
            'fifteen': 'í”¼í”„í‹´', 'sixteen': 'ì‹ìŠ¤í‹´', 'seventeen': 'ì„¸ë¸í‹´', 'eighteen': 'ì—ì´í‹´',
            'nineteen': 'ë‚˜ì¸í‹´', 'twenty': 'íŠ¸ì›¬í‹°', 'thirty': 'ì¨í‹°', 'forty': 'í¬í‹°',
            'fifty': 'í”¼í”„í‹°', 'sixty': 'ì‹ìŠ¤í‹°', 'seventy': 'ì„¸ë¸í‹°', 'eighty': 'ì—ì´í‹°',
            'ninety': 'ë‚˜ì¸í‹°', 'hundred': 'í—Œë“œë ˆë“œ', 'thousand': 'ì‚¬ìš°ì „ë“œ', 'million': 'ë°€ë¦¬ì–¸',

            # ìì£¼ ì‚¬ìš©ë˜ëŠ” ë™ì‚¬ (í™•ì¥)
            'go': 'ê³ ', 'come': 'ì»´', 'see': 'ì‹œ', 'look': 'ë£©', 'watch': 'ì™€ì¹˜',
            'want': 'ì›íŠ¸', 'need': 'ë‹ˆë“œ', 'have': 'í•´ë¸Œ', 'get': 'ê²Ÿ', 'give': 'ê¸°ë¸Œ',
            'take': 'í…Œì´í¬', 'make': 'ë©”ì´í¬', 'do': 'ë‘', 'did': 'ë””ë“œ', 'done': 'ë˜',
            'put': 'í’‹', 'bring': 'ë¸Œë§', 'think': 'ëµí¬', 'know': 'ë…¸', 'understand': 'ì–¸ë”ìŠ¤íƒ ë“œ',
            'say': 'ì„¸ì´', 'tell': 'í…”', 'speak': 'ìŠ¤í”¼í¬', 'talk': 'í† í¬', 'listen': 'ë¦¬ìŠ¨',
            'hear': 'íˆì–´', 'eat': 'ì´íŠ¸', 'drink': 'ë“œë§í¬', 'sleep': 'ìŠ¬ë¦½', 'work': 'ì›Œí¬',
            'play': 'í”Œë ˆì´', 'read': 'ë¦¬ë“œ', 'write': 'ë¼ì´íŠ¸', 'learn': 'ëŸ°', 'teach': 'í‹°ì¹˜',
            'help': 'í—¬í”„', 'try': 'íŠ¸ë¼ì´', 'use': 'ìœ ì¦ˆ', 'buy': 'ë°”ì´', 'sell': 'ì…€',
            'pay': 'í˜ì´', 'cost': 'ì½”ìŠ¤íŠ¸', 'find': 'íŒŒì¸ë“œ', 'lose': 'ë£¨ì¦ˆ', 'win': 'ìœˆ',
            'stop': 'ìŠ¤íƒ‘', 'start': 'ìŠ¤íƒ€íŠ¸', 'begin': 'ë¹„ê¸´', 'end': 'ì—”ë“œ', 'finish': 'í”¼ë‹ˆì‹œ',
            'open': 'ì˜¤í”ˆ', 'close': 'í´ë¡œì¦ˆ', 'turn': 'í„´', 'move': 'ë¬´ë¸Œ', 'walk': 'ì›Œí¬',
            'run': 'ëŸ°', 'drive': 'ë“œë¼ì´ë¸Œ', 'fly': 'í”Œë¼ì´', 'travel': 'íŠ¸ë˜ë¸”',

            # ëŒ€ëª…ì‚¬ ë° ì†Œìœ ê²©
            'i': 'ì•„ì´', 'me': 'ë¯¸', 'my': 'ë§ˆì´', 'mine': 'ë§ˆì¸', 'myself': 'ë§ˆì´ì…€í”„',
            'you': 'ìœ ', 'your': 'ìœ ì–´', 'yours': 'ìœ ì–´ìŠ¤', 'yourself': 'ìœ ì–´ì…€í”„',
            'he': 'íˆ', 'him': 'í˜', 'his': 'íˆì¦ˆ', 'himself': 'í˜ì…€í”„',
            'she': 'ì‰¬', 'her': 'í—ˆ', 'hers': 'í—ˆì¦ˆ', 'herself': 'í—ˆì…€í”„',
            'it': 'ì‡', 'its': 'ì‡ì¸ ', 'itself': 'ì‡ì…€í”„',
            'we': 'ìœ„', 'us': 'ì–´ìŠ¤', 'our': 'ì•„ì›Œ', 'ours': 'ì•„ì›Œì¦ˆ', 'ourselves': 'ì•„ì›Œì…€ë¸Œì¦ˆ',
            'they': 'ë°ì´', 'them': 'ë€', 'their': 'ë°ì–´', 'theirs': 'ë°ì–´ì¦ˆ', 'themselves': 'ë€ì…€ë¸Œì¦ˆ',
            'this': 'ë””ìŠ¤', 'that': 'ëŒ“', 'these': 'ë””ì¦ˆ', 'those': 'ë„ì¦ˆ',
            'who': 'í›„', 'what': 'ì™“', 'where': 'ì›¨ì–´', 'when': 'ì›¬', 'why': 'ì™€ì´', 'how': 'í•˜ìš°',

            # ì ‘ì†ì‚¬/ì „ì¹˜ì‚¬ (í™•ì¥)
            'and': 'ì•¤ë“œ', 'or': 'ì˜¤ì–´', 'but': 'ë²—', 'so': 'ì†Œ', 'because': 'ë¹„ì½”ì¦ˆ',
            'if': 'ì´í”„', 'when': 'ì›¬', 'while': 'ì™€ì¼', 'until': 'ì–¸í‹¸', 'since': 'ì‹ ìŠ¤',
            'before': 'ë¹„í¬ì–´', 'after': 'ì• í”„í„°', 'during': 'ë“€ë§',
            'in': 'ì¸', 'on': 'ì˜¨', 'at': 'ì•³', 'to': 'íˆ¬', 'for': 'í¬', 'with': 'ìœ„ë“œ',
            'without': 'ìœ„ë‹¤ì›ƒ', 'by': 'ë°”ì´', 'from': 'í”„ë¡¬', 'about': 'ì–´ë°”ì›ƒ',
            'under': 'ì–¸ë”', 'over': 'ì˜¤ë²„', 'above': 'ì–´ë³´ë¸Œ', 'below': 'ë¹Œë¡œ',
            'between': 'ë¹„íŠ¸ìœˆ', 'among': 'ì–´ëª½', 'through': 'ì“°ë£¨', 'across': 'ì–´í¬ë¡œìŠ¤',
            'into': 'ì¸íˆ¬', 'onto': 'ì˜¨íˆ¬', 'off': 'ì˜¤í”„', 'out': 'ì•„ì›ƒ', 'up': 'ì—…', 'down': 'ë‹¤ìš´',

            # í˜•ìš©ì‚¬ (í™•ì¥)
            'big': 'ë¹…', 'small': 'ìŠ¤ëª°', 'large': 'ë¼ì§€', 'little': 'ë¦¬í‹€', 'tiny': 'íƒ€ì´ë‹ˆ',
            'long': 'ë¡±', 'short': 'ì‡¼íŠ¸', 'tall': 'í†¨', 'high': 'í•˜ì´', 'low': 'ë¡œ',
            'wide': 'ì™€ì´ë“œ', 'narrow': 'ë‚´ë¡œ', 'thick': 'ì”©', 'thin': 'ì”¬',
            'hot': 'í•«', 'cold': 'ì½œë“œ', 'warm': 'ì›œ', 'cool': 'ì¿¨', 'dry': 'ë“œë¼ì´', 'wet': 'ì›»',
            'clean': 'í´ë¦°', 'dirty': 'ë”í‹°', 'new': 'ë‰´', 'old': 'ì˜¬ë“œ', 'young': 'ì˜',
            'fast': 'íŒ¨ìŠ¤íŠ¸', 'slow': 'ìŠ¬ë¡œ', 'quick': 'í€µ', 'easy': 'ì´ì§€', 'difficult': 'ë””í”¼ì»¬íŠ¸',
            'hard': 'í•˜ë“œ', 'soft': 'ì†Œí”„íŠ¸', 'light': 'ë¼ì´íŠ¸', 'heavy': 'í—¤ë¹„',
            'strong': 'ìŠ¤íŠ¸ë¡±', 'weak': 'ìœ„í¬', 'safe': 'ì„¸ì´í”„', 'dangerous': 'ë°ì¸ì €ëŸ¬ìŠ¤',
            'beautiful': 'ë·°í‹°í’€', 'ugly': 'ì–´ê¸€ë¦¬', 'pretty': 'í”„ë¦¬í‹°', 'handsome': 'í•¸ì„¬',
            'smart': 'ìŠ¤ë§ˆíŠ¸', 'stupid': 'ìŠ¤íˆ¬í”¼ë“œ', 'clever': 'í´ë ˆë²„', 'funny': 'í¼ë‹ˆ',
            'serious': 'ì‹œë¦¬ì–´ìŠ¤', 'happy': 'í•´í”¼', 'sad': 'ìƒˆë“œ', 'angry': 'ì•µê·¸ë¦¬',
            'excited': 'ìµì‚¬ì´í‹°ë“œ', 'tired': 'íƒ€ì´ì–´ë“œ', 'hungry': 'í—ê·¸ë¦¬', 'thirsty': 'ì¨ìŠ¤í‹°',

            # ë¶€ì‚¬
            'very': 'ë² ë¦¬', 'really': 'ë¦¬ì–¼ë¦¬', 'quite': 'ì½°ì´íŠ¸', 'too': 'íˆ¬', 'enough': 'ì´ë„ˆí”„',
            'much': 'ë¨¸ì¹˜', 'many': 'ë©”ë‹ˆ', 'more': 'ëª¨ì–´', 'most': 'ëª¨ìŠ¤íŠ¸',
            'less': 'ë ˆìŠ¤', 'least': 'ë¦¬ìŠ¤íŠ¸', 'few': 'í“¨', 'little': 'ë¦¬í‹€',
            'some': 'ì¸', 'any': 'ì• ë‹ˆ', 'all': 'ì˜¬', 'every': 'ì—ë¸Œë¦¬', 'each': 'ì´ì¹˜',
            'both': 'ë³´ìŠ¤', 'either': 'ì•„ì´ë”', 'neither': 'ë‚˜ì´ë”',
            'here': 'íˆì–´', 'there': 'ë°ì–´', 'everywhere': 'ì—ë¸Œë¦¬ì›¨ì–´', 'somewhere': 'ì¸ì›¨ì–´',
            'nowhere': 'ë…¸ì›¨ì–´', 'anywhere': 'ì• ë‹ˆì›¨ì–´',
            'always': 'ì˜¬ì›¨ì´ì¦ˆ', 'never': 'ë„¤ë²„', 'sometimes': 'ì¸íƒ€ì„ì¦ˆ', 'often': 'ì˜¤í”ˆ',
            'usually': 'ìœ ì£¼ì–¼ë¦¬', 'seldom': 'ì…€ë¤', 'rarely': 'ë ˆì–¼ë¦¬',
            'already': 'ì˜¬ë ˆë””', 'yet': 'ì˜›', 'still': 'ìŠ¤í‹¸', 'just': 'ì €ìŠ¤íŠ¸',
            'only': 'ì˜¨ë¦¬', 'also': 'ì˜¬ì†Œ', 'too': 'íˆ¬', 'either': 'ì•„ì´ë”',

            # ìŒì‹ ë° ìŒë£Œ
            'food': 'í‘¸ë“œ', 'water': 'ì›Œí„°', 'coffee': 'ì»¤í”¼', 'tea': 'í‹°', 'milk': 'ë°€í¬',
            'juice': 'ì£¼ìŠ¤', 'beer': 'ë¹„ì–´', 'wine': 'ì™€ì¸', 'bread': 'ë¸Œë ˆë“œ', 'rice': 'ë¼ì´ìŠ¤',
            'meat': 'ë¯¸íŠ¸', 'fish': 'í”¼ì‹œ', 'chicken': 'ì¹˜í‚¨', 'beef': 'ë¹„í”„', 'pork': 'í¬í¬',
            'vegetable': 'ë² ì§€í„°ë¸”', 'fruit': 'í”„ë£¨íŠ¸', 'apple': 'ì• í”Œ', 'banana': 'ë°”ë‚˜ë‚˜',
            'orange': 'ì˜¤ë Œì§€', 'grape': 'ê·¸ë ˆì´í”„', 'strawberry': 'ìŠ¤íŠ¸ë¡œë² ë¦¬',
            'pizza': 'í”¼ì', 'hamburger': 'í–„ë²„ê±°', 'sandwich': 'ìƒŒë“œìœ„ì¹˜', 'salad': 'ìƒëŸ¬ë“œ',
            'soup': 'ìˆ˜í”„', 'cake': 'ì¼€ì´í¬', 'cookie': 'ì¿ í‚¤', 'ice': 'ì•„ì´ìŠ¤', 'cream': 'í¬ë¦¼',

            # ìƒ‰ê¹”
            'red': 'ë ˆë“œ', 'blue': 'ë¸”ë£¨', 'green': 'ê·¸ë¦°', 'yellow': 'ì˜ë¡œ', 'purple': 'í¼í”Œ',
            'orange': 'ì˜¤ë Œì§€', 'pink': 'í•‘í¬', 'brown': 'ë¸Œë¼ìš´', 'gray': 'ê·¸ë ˆì´', 'grey': 'ê·¸ë ˆì´',
            'black': 'ë¸”ë™', 'white': 'í™”ì´íŠ¸', 'silver': 'ì‹¤ë²„', 'gold': 'ê³¨ë“œ',

            # ê°€ì¡± ê´€ê³„
            'family': 'íŒ¨ë°€ë¦¬', 'father': 'íŒŒë”', 'mother': 'ë§ˆë”', 'dad': 'ëŒ€ë“œ', 'mom': 'ë§˜',
            'parent': 'íŒ¨ëŸ°íŠ¸', 'child': 'ì°¨ì¼ë“œ', 'son': 'ì„ ', 'daughter': 'ë„í„°',
            'brother': 'ë¸Œë¼ë”', 'sister': 'ì‹œìŠ¤í„°', 'husband': 'í—ˆì¦ˆë²ˆë“œ', 'wife': 'ì™€ì´í”„',
            'grandfather': 'ê·¸ëœë“œíŒŒë”', 'grandmother': 'ê·¸ëœë“œë§ˆë”', 'uncle': 'ì—‰í´', 'aunt': 'ì•¤íŠ¸',
            'cousin': 'ì»¤ì¦Œ', 'nephew': 'ë„¤í“¨', 'niece': 'ë‹ˆìŠ¤',

            # ì§ì—…
            'job': 'ì¡', 'work': 'ì›Œí¬', 'teacher': 'í‹°ì²˜', 'student': 'ìŠ¤íŠœë˜íŠ¸', 'doctor': 'ë‹¥í„°',
            'nurse': 'ë„ˆìŠ¤', 'lawyer': 'ë¡œì´ì–´', 'engineer': 'ì—”ì§€ë‹ˆì–´', 'manager': 'ë§¤ë‹ˆì €',
            'worker': 'ì›Œì»¤', 'driver': 'ë“œë¼ì´ë²„', 'cook': 'ì¿¡', 'waiter': 'ì›¨ì´í„°',
            'police': 'í´ë¦¬ìŠ¤', 'fire': 'íŒŒì´ì–´', 'fighter': 'íŒŒì´í„°',

            # ì¥ì†Œ
            'home': 'í™ˆ', 'house': 'í•˜ìš°ìŠ¤', 'school': 'ìŠ¤ì¿¨', 'office': 'ì˜¤í”¼ìŠ¤', 'hospital': 'í•˜ìŠ¤í”¼íƒˆ',
            'store': 'ìŠ¤í† ì–´', 'shop': 'ìƒµ', 'market': 'ë§ˆì¼“', 'bank': 'ë±…í¬', 'post': 'í¬ìŠ¤íŠ¸',
            'restaurant': 'ë ˆìŠ¤í† ë‘', 'hotel': 'í˜¸í…”', 'airport': 'ì—ì–´í¬íŠ¸', 'station': 'ìŠ¤í…Œì´ì…˜',
            'park': 'íŒŒí¬', 'beach': 'ë¹„ì¹˜', 'mountain': 'ë§ˆìš´í‹´', 'river': 'ë¦¬ë²„', 'lake': 'ë ˆì´í¬',
            'city': 'ì‹œí‹°', 'town': 'íƒ€ìš´', 'country': 'ì»¨íŠ¸ë¦¬', 'street': 'ìŠ¤íŠ¸ë¦¬íŠ¸', 'road': 'ë¡œë“œ',

            # êµí†µìˆ˜ë‹¨
            'car': 'ì¹´', 'bus': 'ë²„ìŠ¤', 'train': 'íŠ¸ë ˆì¸', 'plane': 'í”Œë ˆì¸', 'ship': 'ì‰½',
            'boat': 'ë³´íŠ¸', 'bicycle': 'ë°”ì´ì‹œí´', 'bike': 'ë°”ì´í¬', 'taxi': 'íƒì‹œ', 'subway': 'ì„œë¸Œì›¨ì´',

            # ë™ë¬¼
            'animal': 'ì• ë‹ˆë©€', 'dog': 'ë„ê·¸', 'cat': 'ìº£', 'bird': 'ë²„ë“œ', 'fish': 'í”¼ì‹œ',
            'horse': 'í˜¸ìŠ¤', 'cow': 'ì¹´ìš°', 'pig': 'í”¼ê·¸', 'sheep': 'ì‰½', 'chicken': 'ì¹˜í‚¨',
            'tiger': 'íƒ€ì´ê±°', 'lion': 'ë¼ì´ì–¸', 'elephant': 'ì—˜ë¦¬í€íŠ¸', 'monkey': 'ëª½í‚¤',

            # ë‚ ì”¨
            'weather': 'ì›¨ë”', 'sunny': 'ì¨ë‹ˆ', 'cloudy': 'í´ë¼ìš°ë””', 'rainy': 'ë ˆì´ë‹ˆ',
            'snowy': 'ìŠ¤ë…¸ìœ„', 'windy': 'ìœˆë””', 'storm': 'ìŠ¤í†°', 'thunder': 'ì„ ë”',
            'rain': 'ë ˆì¸', 'snow': 'ìŠ¤ë…¸', 'wind': 'ìœˆë“œ', 'sun': 'ì„ ', 'cloud': 'í´ë¼ìš°ë“œ',

            # ê³„ì ˆê³¼ ë‹¬
            'spring': 'ìŠ¤í”„ë§', 'summer': 'ì„œë¨¸', 'fall': 'í´', 'autumn': 'ì˜¤í…€', 'winter': 'ìœˆí„°',
            'january': 'ì°ìœ ì–´ë¦¬', 'february': 'í˜ë¸Œë£¨ì–´ë¦¬', 'march': 'ë§ˆì¹˜', 'april': 'ì—ì´í”„ë¦´',
            'may': 'ë©”ì´', 'june': 'ì¤€', 'july': 'ì¤„ë¼ì´', 'august': 'ì˜¤ê±°ìŠ¤íŠ¸',
            'september': 'ì…‰í…œë²„', 'october': 'ì˜¥í† ë²„', 'november': 'ë…¸ë²°ë²„', 'december': 'ë””ì…ˆë²„',

            # ìš”ì¼
            'monday': 'ë¨¼ë°ì´', 'tuesday': 'íŠœì¦ˆë°ì´', 'wednesday': 'ì›¬ì¦ˆë°ì´', 'thursday': 'ì¨ì¦ˆë°ì´',
            'friday': 'í”„ë¼ì´ë°ì´', 'saturday': 'ìƒˆí„°ë°ì´', 'sunday': 'ì„ ë°ì´',

            # ì‹ ì²´ ë¶€ìœ„
            'body': 'ë°”ë””', 'head': 'í—¤ë“œ', 'face': 'í˜ì´ìŠ¤', 'eye': 'ì•„ì´', 'nose': 'ë…¸ì¦ˆ',
            'mouth': 'ë§ˆìš°ìŠ¤', 'ear': 'ì´ì–´', 'hair': 'í—¤ì–´', 'neck': 'ë„¥', 'shoulder': 'ìˆ„ë”',
            'arm': 'ì•”', 'hand': 'í•¸ë“œ', 'finger': 'í•‘ê±°', 'leg': 'ë ˆê·¸', 'foot': 'í’‹',
            'back': 'ë°±', 'stomach': 'ìŠ¤í„°ë§‰', 'heart': 'í•˜íŠ¸',

            # ì˜ë¥˜
            'clothes': 'í´ë¡œì¦ˆ', 'shirt': 'ì…”íŠ¸', 'pants': 'íŒ¬ì¸ ', 'dress': 'ë“œë ˆìŠ¤', 'skirt': 'ìŠ¤ì»¤íŠ¸',
            'jacket': 'ì¬í‚·', 'coat': 'ì½”íŠ¸', 'shoes': 'ìŠˆì¦ˆ', 'hat': 'í–‡', 'cap': 'ìº¡',
            'socks': 'ì‚­ìŠ¤', 'gloves': 'ê¸€ëŸ¬ë¸Œì¦ˆ', 'belt': 'ë²¨íŠ¸', 'tie': 'íƒ€ì´',

            # ê°ì • í‘œí˜„
            'love': 'ëŸ¬ë¸Œ', 'like': 'ë¼ì´í¬', 'hate': 'í—¤ì´íŠ¸', 'enjoy': 'ì¸ì¡°ì´', 'prefer': 'í”„ë¦¬í¼',
            'feel': 'í•„', 'emotion': 'ì´ëª¨ì…˜', 'smile': 'ìŠ¤ë§ˆì¼', 'laugh': 'ë˜í”„', 'cry': 'í¬ë¼ì´',
            'worry': 'ì›Œë¦¬', 'fear': 'í”¼ì–´', 'hope': 'í˜¸í”„', 'dream': 'ë“œë¦¼',
        }

        # ê³ ê¸‰ ìŒì„±í•™ì  ê·œì¹™ë“¤
        self.phonetic_rules = [
            # ë³µí•© ììŒ ì¡°í•©ë“¤
            ('tion', 'ì…˜'), ('sion', 'ì…˜'), ('cial', 'ì…œ'), ('tial', 'ì…œ'),
            ('ough', 'ì–´í”„'), ('augh', 'ì˜¤í”„'), ('eigh', 'ì—ì´'),
            ('ght', 'ã…Œ'), ('ck', 'ã…‹'), ('ng', 'ã…‡'),
            ('th', 'ã……'), ('sh', 'ì‰¬'), ('ch', 'ì¹˜'), ('ph', 'ã…'),
            ('wh', 'ìš°'), ('qu', 'í'), ('kn', 'ã„´'), ('wr', 'ã„¹'),
            ('mb', 'ã…'), ('bt', 'ã…Œ'), ('mn', 'ã…'),

            # ëª¨ìŒ ì¡°í•©ë“¤
            ('ai', 'ì—ì´'), ('ay', 'ì—ì´'), ('ee', 'ì´'), ('ea', 'ì´'),
            ('ie', 'ì•„ì´'), ('oe', 'ì˜¤'), ('ue', 'ìœ '), ('ui', 'ìœ ì´'),
            ('oo', 'ìš°'), ('ou', 'ì•„ìš°'), ('ow', 'ì•„ìš°'), ('au', 'ì˜¤'),
            ('aw', 'ì˜¤'), ('ew', 'ìœ '), ('ey', 'ì—ì´'), ('oy', 'ì˜¤ì´'),

            # ììŒ + ëª¨ìŒ ì¡°í•©
            ('ce', 'ìŠ¤'), ('ci', 'ì‹œ'), ('cy', 'ì‹œ'),
            ('ge', 'ì§€'), ('gi', 'ì§€'), ('gy', 'ì§€'),
            ('dge', 'ì§€'), ('tch', 'ì¹˜'),

            # ì–´ë¯¸ ë³€í™”
            ('ed', 'ë“œ'), ('ing', 'ì‰'), ('er', 'ì–´'), ('est', 'ì—ìŠ¤íŠ¸'),
            ('ly', 'ë¦¬'), ('ty', 'í‹°'), ('ry', 'ë¦¬'), ('ny', 'ë‹ˆ'),
            ('ful', 'í’€'), ('less', 'ë ˆìŠ¤'), ('ness', 'ë„¤ìŠ¤'),
        ]

        # ë‹¨ì¼ ë¬¸ì ë§¤í•‘ (ê°œì„ ë¨)
        self.single_char_map = {
            # ëª¨ìŒë“¤
            'a': 'ì•„', 'e': 'ì—', 'i': 'ì´', 'o': 'ì˜¤', 'u': 'ìš°', 'y': 'ì´',

            # ììŒë“¤ (ìƒí™©ë³„ ë‹¤ë¥¸ ë°œìŒ)
            'b': 'ã…‚', 'c': 'ã…‹', 'd': 'ã„·', 'f': 'ã…', 'g': 'ã„±',
            'h': 'ã…', 'j': 'ã…ˆ', 'k': 'ã…‹', 'l': 'ã„¹', 'm': 'ã…',
            'n': 'ã„´', 'p': 'ã…', 'q': 'ã…‹', 'r': 'ã„¹', 's': 'ã……',
            't': 'ã…Œ', 'v': 'ã…‚', 'w': 'ã…‡', 'x': 'ã…‹ã……', 'z': 'ã…ˆ'
        }

    def advanced_phonetic_conversion(self, word):
        """ê³ ê¸‰ ìŒì„±í•™ì  ë³€í™˜"""
        word = word.lower().strip()

        # ì‚¬ì „ì— ìˆëŠ” ë‹¨ì–´ëŠ” ë°”ë¡œ ë°˜í™˜
        if word in self.word_dict:
            return self.word_dict[word]

        result = word

        # 1ë‹¨ê³„: ë³µí•© íŒ¨í„´ ì ìš©
        for pattern, replacement in self.phonetic_rules:
            result = result.replace(pattern, replacement)

        # 2ë‹¨ê³„: ë‚¨ì€ ë¬¸ìë“¤ì„ ê°œë³„ ë³€í™˜
        final_result = ""
        i = 0
        while i < len(result):
            char = result[i]

            # í•œê¸€ì´ ì´ë¯¸ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€
            if ord(char) >= 0xAC00 and ord(char) <= 0xD7A3:  # í•œê¸€ ì™„ì„±í˜• ë²”ìœ„
                final_result += char
            elif char in 'ã„±ã„´ã„·ã„¹ã…ã…‚ã……ã…‡ã…ˆã…Šã…‹ã…Œã…ã…ã…ã…‘ã…“ã…•ã…—ã…›ã…œã… ã…¡ã…£':  # í•œê¸€ ìëª¨
                final_result += char
            elif char in self.single_char_map:
                final_result += self.single_char_map[char]
            elif char in ' .,!?;:-_()[]{}"\'/\\':
                final_result += char
            else:
                # ì•Œ ìˆ˜ ì—†ëŠ” ë¬¸ìëŠ” ìŒì„±í•™ì ìœ¼ë¡œ ì¶”ì •
                final_result += self.guess_pronunciation(char)

            i += 1

        return final_result

    def guess_pronunciation(self, char):
        """ì•Œ ìˆ˜ ì—†ëŠ” ë¬¸ìì˜ ë°œìŒ ì¶”ì •"""
        # ìˆ«ì ì²˜ë¦¬
        number_map = {
            '0': 'ì œë¡œ', '1': 'ì›', '2': 'íˆ¬', '3': 'ì“°ë¦¬', '4': 'í¬',
            '5': 'íŒŒì´ë¸Œ', '6': 'ì‹ìŠ¤', '7': 'ì„¸ë¸', '8': 'ì—ì´íŠ¸', '9': 'ë‚˜ì¸'
        }

        if char in number_map:
            return number_map[char]

        # íŠ¹ìˆ˜ ë¬¸ìëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
        if not char.isalpha():
            return char

        # ê¸°ë³¸ ììŒ/ëª¨ìŒ ë§¤í•‘ ì‚¬ìš©
        return self.single_char_map.get(char, char)

    def handle_contractions(self, text):
        """ì¶•ì•½í˜• ì²˜ë¦¬"""
        contractions = {
            "i'm": "ì•„ì´ ì•°", "you're": "ìœ  ì•„", "he's": "íˆ ì´ì¦ˆ", "she's": "ì‰¬ ì´ì¦ˆ",
            "it's": "ì‡ ì´ì¦ˆ", "we're": "ìœ„ ì•„", "they're": "ë°ì´ ì•„",
            "isn't": "ì´ì¦ŒíŠ¸", "aren't": "ì•„ëŸ°íŠ¸", "wasn't": "ì™€ì¦ŒíŠ¸", "weren't": "ì›ŒëŸ°íŠ¸",
            "don't": "ëˆíŠ¸", "doesn't": "ë”ì¦ŒíŠ¸", "didn't": "ë””ë“ íŠ¸",
            "won't": "ì›íŠ¸", "wouldn't": "ìš°ë“ íŠ¸", "can't": "ìº”íŠ¸", "couldn't": "ì¿ ë“ íŠ¸",
            "shouldn't": "ìŠˆë“ íŠ¸", "mustn't": "ë¨¸ìŠ¨íŠ¸",
            "i'll": "ì•„ì¼", "you'll": "ìœ¨", "he'll": "í", "she'll": "ì‰´",
            "we'll": "ìœŒ", "they'll": "ë°ì¼",
            "i've": "ì•„ì´ë¸Œ", "you've": "ìœ ë¸Œ", "we've": "ìœ„ë¸Œ", "they've": "ë°ì´ë¸Œ",
            "i'd": "ì•„ì´ë“œ", "you'd": "ìœ ë“œ", "he'd": "íˆë“œ", "she'd": "ì‰¬ë“œ",
            "we'd": "ìœ„ë“œ", "they'd": "ë°ì´ë“œ",
        }

        # ì¶•ì•½í˜•ì„ ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬í•´ì„œ ì²˜ë¦¬
        for contraction, expanded in contractions.items():
            text = re.sub(r'\b' + contraction + r'\b', expanded, text, flags=re.IGNORECASE)

        return text

    def handle_special_endings(self, word):
        """íŠ¹ìˆ˜ ì–´ë¯¸ ì²˜ë¦¬"""
        # -s ë³µìˆ˜í˜• ì²˜ë¦¬
        if word.endswith('s') and len(word) > 1:
            base_word = word[:-1]
            if base_word in self.word_dict:
                return self.word_dict[base_word] + 'ìŠ¤'

        # -ed ê³¼ê±°í˜• ì²˜ë¦¬
        if word.endswith('ed') and len(word) > 2:
            base_word = word[:-2]
            if base_word in self.word_dict:
                return self.word_dict[base_word] + 'ë“œ'

        # -ing ì§„í–‰í˜• ì²˜ë¦¬
        if word.endswith('ing') and len(word) > 3:
            base_word = word[:-3]
            if base_word in self.word_dict:
                return self.word_dict[base_word] + 'ì‰'

        # -ly ë¶€ì‚¬ ì²˜ë¦¬
        if word.endswith('ly') and len(word) > 2:
            base_word = word[:-2]
            if base_word in self.word_dict:
                return self.word_dict[base_word] + 'ë¦¬'

        return None

    def convert_text(self, english_text):
        """ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ í•œê¸€ ë°œìŒìœ¼ë¡œ ë³€í™˜ (ê°œì„ ëœ ë²„ì „)"""
        if not english_text:
            return ""

        # 1ë‹¨ê³„: ì¶•ì•½í˜• ì²˜ë¦¬
        text = self.handle_contractions(english_text)

        # 2ë‹¨ê³„: ë¬¸ì¥ë¶€í˜¸ ë³´ì¡´ì„ ìœ„í•œ ì²˜ë¦¬
        sentences = re.split(r'([.!?]+)', text)
        converted_sentences = []

        for sentence in sentences:
            if re.match(r'^[.!?]+$', sentence):
                converted_sentences.append(sentence)
                continue

            # 3ë‹¨ê³„: ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë¶„ë¦¬ (êµ¬ë‘ì  ë³´ì¡´)
            words = re.findall(r'\b\w+\b|[^\w\s]', sentence.lower())
            converted_words = []

            for word in words:
                if not word.isalpha():
                    # êµ¬ë‘ì ì´ë‚˜ ìˆ«ìëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
                    converted_words.append(word)
                    continue

                # 4ë‹¨ê³„: íŠ¹ìˆ˜ ì–´ë¯¸ ì²˜ë¦¬ ì‹œë„
                special_result = self.handle_special_endings(word)
                if special_result:
                    converted_words.append(special_result)
                    continue

                # 5ë‹¨ê³„: ì¼ë°˜ ë³€í™˜ ì²˜ë¦¬
                converted_word = self.advanced_phonetic_conversion(word)
                converted_words.append(converted_word)

            if converted_words:
                converted_sentences.append(' '.join(converted_words))

        # ìµœì¢… ê²°ê³¼ ì¡°í•©
        result = ''.join(converted_sentences)

        # í›„ì²˜ë¦¬: ë¶ˆí•„ìš”í•œ ê³µë°± ì •ë¦¬
        result = re.sub(r'\s+', ' ', result).strip()

        return result

    def convert_with_context(self, english_text, context_type="general"):
        """ë¬¸ë§¥ì„ ê³ ë ¤í•œ ë³€í™˜"""
        # ë¬¸ë§¥ë³„ íŠ¹ìˆ˜ ì²˜ë¦¬
        if context_type == "formal":
            # ê²©ì‹ì²´ ë³€í™˜
            english_text = english_text.replace("hi", "hello")
            english_text = english_text.replace("yeah", "yes")

        elif context_type == "casual":
            # êµ¬ì–´ì²´ ë³€í™˜
            english_text = english_text.replace("going to", "gonna")
            english_text = english_text.replace("want to", "wanna")

        return self.convert_text(english_text)

    def get_pronunciation_confidence(self, word):
        """ë°œìŒ ë³€í™˜ ì‹ ë¢°ë„ ë°˜í™˜"""
        word = word.lower().strip()

        if word in self.word_dict:
            return 0.95  # ì‚¬ì „ì— ìˆëŠ” ë‹¨ì–´ëŠ” ë†’ì€ ì‹ ë¢°ë„

        # ê·œì¹™ ê¸°ë°˜ íŒ¨í„´ì´ ì ìš©ë˜ëŠ”ì§€ í™•ì¸
        rule_matches = sum(1 for pattern, _ in self.phonetic_rules if pattern in word)

        if rule_matches >= 2:
            return 0.8  # ì—¬ëŸ¬ ê·œì¹™ì´ ì ìš©ë˜ë©´ ë†’ì€ ì‹ ë¢°ë„
        elif rule_matches == 1:
            return 0.6  # í•˜ë‚˜ì˜ ê·œì¹™ì´ ì ìš©ë˜ë©´ ì¤‘ê°„ ì‹ ë¢°ë„
        else:
            return 0.3  # ì¶”ì¸¡ ê¸°ë°˜ ë³€í™˜ì€ ë‚®ì€ ì‹ ë¢°ë„

    def batch_convert(self, word_list):
        """ë‹¨ì–´ ëª©ë¡ ì¼ê´„ ë³€í™˜"""
        results = []
        for word in word_list:
            converted = self.convert_text(word)
            confidence = self.get_pronunciation_confidence(word)
            results.append({
                'original': word,
                'converted': converted,
                'confidence': confidence
            })
        return results

    def add_custom_word(self, english_word, korean_pronunciation):
        """ì‚¬ìš©ì ì •ì˜ ë‹¨ì–´ ì¶”ê°€"""
        self.word_dict[english_word.lower()] = korean_pronunciation
        print(f"âœ… ì‚¬ìš©ì ë‹¨ì–´ ì¶”ê°€: {english_word} -> {korean_pronunciation}")

    def get_word_variants(self, base_word):
        """ë‹¨ì–´ì˜ ë³€í˜•ë“¤ ìƒì„±"""
        variants = {}
        base_pronunciation = self.word_dict.get(base_word.lower(),
                                               self.advanced_phonetic_conversion(base_word))

        # ë³µìˆ˜í˜•
        variants[f"{base_word}s"] = f"{base_pronunciation}ìŠ¤"

        # ê³¼ê±°í˜• (-ed)
        if not base_word.endswith('e'):
            variants[f"{base_word}ed"] = f"{base_pronunciation}ë“œ"
        else:
            variants[f"{base_word}d"] = f"{base_pronunciation}ë“œ"

        # ì§„í–‰í˜• (-ing)
        if base_word.endswith('e'):
            variants[f"{base_word[:-1]}ing"] = f"{base_pronunciation[:-1]}ì‰"
        else:
            variants[f"{base_word}ing"] = f"{base_pronunciation}ì‰"

        # ë¶€ì‚¬í˜• (-ly)
        if base_word.endswith('y'):
            variants[f"{base_word[:-1]}ily"] = f"{base_pronunciation[:-1]}ì¼ë¦¬"
        else:
            variants[f"{base_word}ly"] = f"{base_pronunciation}ë¦¬"

        return variants

    def analyze_pronunciation_patterns(self, text):
        """ë°œìŒ íŒ¨í„´ ë¶„ì„"""
        words = re.findall(r'\b\w+\b', text.lower())
        analysis = {
            'total_words': len(words),
            'dictionary_matches': 0,
            'rule_based_conversions': 0,
            'guessed_conversions': 0,
            'confidence_distribution': {'high': 0, 'medium': 0, 'low': 0}
        }

        for word in words:
            confidence = self.get_pronunciation_confidence(word)

            if word in self.word_dict:
                analysis['dictionary_matches'] += 1
            elif any(pattern in word for pattern, _ in self.phonetic_rules):
                analysis['rule_based_conversions'] += 1
            else:
                analysis['guessed_conversions'] += 1

            if confidence >= 0.8:
                analysis['confidence_distribution']['high'] += 1
            elif confidence >= 0.5:
                analysis['confidence_distribution']['medium'] += 1
            else:
                analysis['confidence_distribution']['low'] += 1

        return analysis

    def suggest_improvements(self, word):
        """ë°œìŒ ê°œì„  ì œì•ˆ"""
        word = word.lower().strip()
        suggestions = []

        if word not in self.word_dict:
            # ìœ ì‚¬í•œ ë‹¨ì–´ ì°¾ê¸°
            similar_words = []
            for dict_word in self.word_dict.keys():
                if len(word) == len(dict_word):
                    differences = sum(1 for a, b in zip(word, dict_word) if a != b)
                    if differences <= 2:  # 2ê¸€ì ì´í•˜ ì°¨ì´
                        similar_words.append(dict_word)

            if similar_words:
                suggestions.append(f"ìœ ì‚¬í•œ ë‹¨ì–´ë“¤: {', '.join(similar_words[:3])}")

            # ë°œìŒ ê·œì¹™ ì œì•ˆ
            applicable_rules = [pattern for pattern, _ in self.phonetic_rules if pattern in word]
            if applicable_rules:
                suggestions.append(f"ì ìš©ëœ ê·œì¹™ë“¤: {', '.join(applicable_rules)}")

            confidence = self.get_pronunciation_confidence(word)
            suggestions.append(f"ë³€í™˜ ì‹ ë¢°ë„: {confidence:.2f}")

        return suggestions

    def export_dictionary(self, filename="custom_pronunciation_dict.json"):
        """ì‚¬ìš©ì ì‚¬ì „ ë‚´ë³´ë‚´ê¸°"""
        try:
            import json
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.word_dict, f, ensure_ascii=False, indent=2)
            print(f"âœ… ì‚¬ì „ ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {filename}")
        except Exception as e:
            print(f"âŒ ì‚¬ì „ ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")

    def import_dictionary(self, filename="custom_pronunciation_dict.json"):
        """ì‚¬ìš©ì ì‚¬ì „ ê°€ì ¸ì˜¤ê¸°"""
        try:
            import json
            with open(filename, 'r', encoding='utf-8') as f:
                imported_dict = json.load(f)

            # ê¸°ì¡´ ì‚¬ì „ê³¼ ë³‘í•©
            original_size = len(self.word_dict)
            self.word_dict.update(imported_dict)
            new_size = len(self.word_dict)

            print(f"âœ… ì‚¬ì „ ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ: {new_size - original_size}ê°œ ë‹¨ì–´ ì¶”ê°€")
        except Exception as e:
            print(f"âŒ ì‚¬ì „ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")

    def create_pronunciation_report(self, text):
        """ë°œìŒ ë³€í™˜ ë³´ê³ ì„œ ìƒì„±"""
        converted = self.convert_text(text)
        analysis = self.analyze_pronunciation_patterns(text)

        report = f"""
ğŸ“Š ë°œìŒ ë³€í™˜ ë³´ê³ ì„œ
================

ğŸ“ ì›ë¬¸: {text}
ğŸ”Š ë³€í™˜: {converted}

ğŸ“ˆ í†µê³„:
- ì´ ë‹¨ì–´ ìˆ˜: {analysis['total_words']}
- ì‚¬ì „ ë§¤ì¹­: {analysis['dictionary_matches']}ê°œ
- ê·œì¹™ ê¸°ë°˜: {analysis['rule_based_conversions']}ê°œ  
- ì¶”ì¸¡ ë³€í™˜: {analysis['guessed_conversions']}ê°œ

ğŸ¯ ì‹ ë¢°ë„ ë¶„í¬:
- ë†’ìŒ (80%+): {analysis['confidence_distribution']['high']}ê°œ
- ì¤‘ê°„ (50-80%): {analysis['confidence_distribution']['medium']}ê°œ
- ë‚®ìŒ (50% ë¯¸ë§Œ): {analysis['confidence_distribution']['low']}ê°œ

ğŸ’¡ ì „ì²´ ì‹ ë¢°ë„: {(analysis['dictionary_matches'] + analysis['rule_based_conversions'] * 0.7) / analysis['total_words'] * 100:.1f}%
"""
        return report


# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤
def test_pronunciation_converter():
    """ë°œìŒ ë³€í™˜ê¸° í…ŒìŠ¤íŠ¸"""
    converter = EnglishToKoreanPronunciation()

    test_sentences = [
        "Hello, how are you today?",
        "I'm going to the store to buy some food.",
        "The weather is really nice and sunny.",
        "She's working on her computer right now.",
        "We'll meet at the restaurant at seven o'clock.",
        "Can you help me with this difficult problem?",
        "The children are playing in the beautiful garden.",
        "I'd like to order a hamburger and french fries, please.",
        "Technology is changing our lives very quickly.",
        "Happy birthday! I hope you have a wonderful day!"
    ]

    print("ğŸ§ª ë°œìŒ ë³€í™˜ê¸° í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    for i, sentence in enumerate(test_sentences, 1):
        print(f"\n{i}. ì›ë¬¸: {sentence}")
        converted = converter.convert_text(sentence)
        print(f"   ë³€í™˜: {converted}")

        # ë¶„ì„ ì •ë³´
        analysis = converter.analyze_pronunciation_patterns(sentence)
        confidence = (analysis['dictionary_matches'] + analysis['rule_based_conversions'] * 0.7) / analysis['total_words'] * 100
        print(f"   ì‹ ë¢°ë„: {confidence:.1f}%")

def demo_advanced_features():
    """ê³ ê¸‰ ê¸°ëŠ¥ ë°ëª¨"""
    converter = EnglishToKoreanPronunciation()

    print("\nğŸš€ ê³ ê¸‰ ê¸°ëŠ¥ ë°ëª¨")
    print("=" * 40)

    # ì‚¬ìš©ì ë‹¨ì–´ ì¶”ê°€
    print("\n1. ì‚¬ìš©ì ë‹¨ì–´ ì¶”ê°€:")
    converter.add_custom_word("smartphone", "ìŠ¤ë§ˆíŠ¸í°")
    converter.add_custom_word("blockchain", "ë¸”ë¡ì²´ì¸")

    # ë‹¨ì–´ ë³€í˜• ìƒì„±
    print("\n2. ë‹¨ì–´ ë³€í˜• ìƒì„±:")
    variants = converter.get_word_variants("play")
    for variant, pronunciation in variants.items():
        print(f"   {variant} -> {pronunciation}")

    # ë°œìŒ ë³´ê³ ì„œ
    print("\n3. ë°œìŒ ë³€í™˜ ë³´ê³ ì„œ:")
    sample_text = "I love technology and smartphones!"
    report = converter.create_pronunciation_report(sample_text)
    print(report)


if __name__ == "__main__":
    # ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_pronunciation_converter()
    demo_advanced_features()