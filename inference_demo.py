# -*- coding: utf-8 -*-
"""infer-v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SslYhVo9ONE-vy8oqMjhSRc_zV8x-d_7

# SCE-TTS: 음성합성 데모

이 문서는 SCE-TTS 프로젝트의 음성 합성 데모입니다.

이 데모에 대한 더 자세한 정보는 아래 링크에서 확인하실 수 있습니다.  
https://sce-tts.github.io/

## 1. 구글 드라이브 마운트

음성합성을 위해 학습한 모델이 있는 구글 드라이브를 마운트합니다.  
마운트할 구글 드라이브 내에 다음 파일들이 존재하는지 꼭 확인해주세요.

- `/Colab Notebooks/data/glowtts-v2/model_file.pth.tar`
- `/Colab Notebooks/data/glowtts-v2/config.json`
- `/Colab Notebooks/data/hifigan-v2/model_file.pth.tar`
- `/Colab Notebooks/data/hifigan-v2/config.json`


(존재하지 않는다면, [glowtts-v2.zip](https://drive.google.com/file/d/1DMKLdfZ_gzc_z0qDod6_G8fEXj0zCHvC/view?usp=sharing), [hifigan-v2.zip](https://drive.google.com/file/d/1vRxp1RH-U7gSzWgyxnKY4h_7pB3tjPmU/view?usp=sharing)을 내려받아 준비해주세요.)

만약 아래에 `Enter your authorization code:`과 같은 메시지가 출력될 경우,  
같이 출력된 링크에 접속하여, 마운트할 구글 계정을 선택하신 후, 인증 코드를 복사하여 입력해주세요.
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content
!apt-get update
!apt-get install -y python3.8 python3.8-dev python3.8-venv
!python3.8 -m venv tts_env
!tts_env/bin/pip install --upgrade pip
!git clone --depth 1 https://github.com/sce-tts/TTS.git -b sce-tts
# %cd /content/TTS
!/content/tts_env/bin/python setup.py develop

!/content/tts_env/bin/pip install numpy torch scipy

"""## 2. 필수 라이브러리 및 함수 불러오기

실행에 필요한 라이브러리 및 함수를 불러옵니다.

이 과정은 약 10분 정도 소요될 수 있습니다.
"""

import os
import sys
from pathlib import Path

# Commented out IPython magic to ensure Python compatibility.
# %cd /content

# 저장소 클론
!git clone --depth 1 https://github.com/sce-tts/TTS.git -b sce-tts
!git clone --depth 1 https://github.com/sce-tts/g2pK.git

# TTS 설치
# %cd /content/TTS
!/content/tts_env/bin/pip install -q --no-cache-dir -e .

# g2pK 설치
# %cd /content/g2pK
!/content/tts_env/bin/pip install -q --no-cache-dir konlpy jamo nltk python-mecab-ko
!/content/tts_env/bin/pip install -q --no-cache-dir -e .

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/g2pK

# g2pk 모듈 테스트
!/content/tts_env/bin/python -c "import g2pk; g2p = g2pk.G2p(); print('g2pk successfully loaded')"

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/TTS

# pysbd 설치
!/content/tts_env/bin/pip install pysbd

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/TTS

import re
import sys
from unicodedata import normalize
import IPython.display as ipd
from TTS.utils.synthesizer import Synthesizer
from TTS.tts.configs.glow_tts_config import GlowTTSConfig
from TTS.vocoder.configs.hifigan_config import HifiganConfig
import g2pk

# symbols 정의 (TTS에서 제공하는 기본 심볼 세트)
from TTS.tts.utils.text.symbols import symbols

# Synthesizer 초기화
def initialize_synthesizer():
    tts_checkpoint = "/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/best_model.pth.tar"
    tts_config_path = "/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/config.json"
    vocoder_checkpoint = "/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/model_file.pth.tar"
    vocoder_config_path = "/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/config.json"

    synthesizer = Synthesizer(
        tts_checkpoint=tts_checkpoint,
        tts_config_path=tts_config_path,
        vocoder_checkpoint=vocoder_checkpoint,
        vocoder_config_path=vocoder_config_path
    )
    return synthesizer

# g2pK 초기화
g2p = g2pk.G2p()

def normalize_text(text):
    text = text.strip()

    for c in ",;:":
        text = text.replace(c, ".")
    text = remove_duplicated_punctuations(text)

    text = jamo_text(text)

    text = g2p.idioms(text)
    text = g2pk.english.convert_eng(text, g2p.cmu)
    text = g2pk.utils.annotate(text, g2p.mecab)
    text = g2pk.numerals.convert_num(text)
    text = re.sub("/[PJEB]", "", text)

    text = alphabet_text(text)

    # remove unreadable characters
    text = normalize("NFD", text)
    text = "".join(c for c in text if c in symbols)
    text = normalize("NFC", text)

    text = text.strip()
    if len(text) == 0:
        return ""

    # only single punctuation
    if text in '.!?':
        return punctuation_text(text)

    # append punctuation if there is no punctuation at the end of the text
    if text[-1] not in '.!?':
        text += '.'

    return text

def remove_duplicated_punctuations(text):
    text = re.sub(r"[.?!]+\?", "?", text)
    text = re.sub(r"[.?!]+!", "!", text)
    text = re.sub(r"[.?!]+\.", ".", text)
    return text

def split_text(text):
    text = remove_duplicated_punctuations(text)

    texts = []
    for subtext in re.findall(r'[^.!?\n]*[.!?\n]', text):
        texts.append(subtext.strip())

    return texts

def alphabet_text(text):
    text = re.sub(r"(a|A)", "에이", text)
    text = re.sub(r"(b|B)", "비", text)
    text = re.sub(r"(c|C)", "씨", text)
    text = re.sub(r"(d|D)", "디", text)
    text = re.sub(r"(e|E)", "이", text)
    text = re.sub(r"(f|F)", "에프", text)
    text = re.sub(r"(g|G)", "쥐", text)
    text = re.sub(r"(h|H)", "에이치", text)
    text = re.sub(r"(i|I)", "아이", text)
    text = re.sub(r"(j|J)", "제이", text)
    text = re.sub(r"(k|K)", "케이", text)
    text = re.sub(r"(l|L)", "엘", text)
    text = re.sub(r"(m|M)", "엠", text)
    text = re.sub(r"(n|N)", "엔", text)
    text = re.sub(r"(o|O)", "오", text)
    text = re.sub(r"(p|P)", "피", text)
    text = re.sub(r"(q|Q)", "큐", text)
    text = re.sub(r"(r|R)", "알", text)
    text = re.sub(r"(s|S)", "에스", text)
    text = re.sub(r"(t|T)", "티", text)
    text = re.sub(r"(u|U)", "유", text)
    text = re.sub(r"(v|V)", "브이", text)
    text = re.sub(r"(w|W)", "더블유", text)
    text = re.sub(r"(x|X)", "엑스", text)
    text = re.sub(r"(y|Y)", "와이", text)
    text = re.sub(r"(z|Z)", "지", text)

    return text

def punctuation_text(text):
    text = re.sub(r"!", "느낌표", text)
    text = re.sub(r"\?", "물음표", text)
    text = re.sub(r"\.", "마침표", text)

    return text

def jamo_text(text):
    text = re.sub(r"ㄱ", "기역", text)
    text = re.sub(r"ㄴ", "니은", text)
    text = re.sub(r"ㄷ", "디귿", text)
    text = re.sub(r"ㄹ", "리을", text)
    text = re.sub(r"ㅁ", "미음", text)
    text = re.sub(r"ㅂ", "비읍", text)
    text = re.sub(r"ㅅ", "시옷", text)
    text = re.sub(r"ㅇ", "이응", text)
    text = re.sub(r"ㅈ", "지읒", text)
    text = re.sub(r"ㅊ", "치읓", text)
    text = re.sub(r"ㅋ", "키읔", text)
    text = re.sub(r"ㅌ", "티읕", text)
    text = re.sub(r"ㅍ", "피읖", text)
    text = re.sub(r"ㅎ", "히읗", text)
    text = re.sub(r"ㄲ", "쌍기역", text)
    text = re.sub(r"ㄸ", "쌍디귿", text)
    text = re.sub(r"ㅃ", "쌍비읍", text)
    text = re.sub(r"ㅆ", "쌍시옷", text)
    text = re.sub(r"ㅉ", "쌍지읒", text)
    text = re.sub(r"ㄳ", "기역시옷", text)
    text = re.sub(r"ㄵ", "니은지읒", text)
    text = re.sub(r"ㄶ", "니은히읗", text)
    text = re.sub(r"ㄺ", "리을기역", text)
    text = re.sub(r"ㄻ", "리을미음", text)
    text = re.sub(r"ㄼ", "리을비읍", text)
    text = re.sub(r"ㄽ", "리을시옷", text)
    text = re.sub(r"ㄾ", "리을티읕", text)
    text = re.sub(r"ㄿ", "리을피읍", text)
    text = re.sub(r"ㅀ", "리을히읗", text)
    text = re.sub(r"ㅄ", "비읍시옷", text)
    text = re.sub(r"ㅏ", "아", text)
    text = re.sub(r"ㅑ", "야", text)
    text = re.sub(r"ㅓ", "어", text)
    text = re.sub(r"ㅕ", "여", text)
    text = re.sub(r"ㅗ", "오", text)
    text = re.sub(r"ㅛ", "요", text)
    text = re.sub(r"ㅜ", "우", text)
    text = re.sub(r"ㅠ", "유", text)
    text = re.sub(r"ㅡ", "으", text)
    text = re.sub(r"ㅣ", "이", text)
    text = re.sub(r"ㅐ", "애", text)
    text = re.sub(r"ㅒ", "얘", text)
    text = re.sub(r"ㅔ", "에", text)
    text = re.sub(r"ㅖ", "예", text)
    text = re.sub(r"ㅘ", "와", text)
    text = re.sub(r"ㅙ", "왜", text)
    text = re.sub(r"ㅚ", "외", text)
    text = re.sub(r"ㅝ", "워", text)
    text = re.sub(r"ㅞ", "웨", text)
    text = re.sub(r"ㅟ", "위", text)
    text = re.sub(r"ㅢ", "의", text)

    return text

def normalize_multiline_text(long_text):
    texts = split_text(long_text)
    normalized_texts = [normalize_text(text).strip() for text in texts]
    return [text for text in normalized_texts if len(text) > 0]

def synthesize(text):
    global synthesizer
    wavs = synthesizer.tts(text, None, None)
    return wavs

# Synthesizer 초기화
synthesizer = initialize_synthesizer()

# 테스트
text = "안녕하세요. SCE-TTS를 사용해 음성을 합성합니다!"
normalized_texts = normalize_multiline_text(text)
for norm_text in normalized_texts:
    print(f"Normalized text: {norm_text}")
    wav = synthesize(norm_text)
    display(ipd.Audio(wav, rate=synthesizer.tts_config.audio["sample_rate"]))

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/TTS
# 
# 
# # synthesize.py 파일 생성
# %%writefile synthesize.py
# import re
# import sys
# from unicodedata import normalize
# import IPython.display as ipd
# from TTS.utils.synthesizer import Synthesizer
# from TTS.tts.configs.glow_tts_config import GlowTTSConfig
# from TTS.vocoder.configs.hifigan_config import HifiganConfig
# import g2pk
# 
# # symbols 정의
# from TTS.tts.utils.text.symbols import symbols
# 
# # Synthesizer 초기화
# def initialize_synthesizer():
#     tts_checkpoint = "/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/best_model.pth.tar"
#     tts_config_path = "/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/config.json"
#     vocoder_checkpoint = "/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/model_file.pth.tar"
#     vocoder_config_path = "/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/config.json"
# 
#     synthesizer = Synthesizer(
#         tts_checkpoint=tts_checkpoint,
#         tts_config_path=tts_config_path,
#         vocoder_checkpoint=vocoder_checkpoint,
#         vocoder_config_path=vocoder_config_path
#     )
#     return synthesizer
# 
# # g2pK 초기화
# g2p = g2pk.G2p()
# 
# def normalize_text(text):
#     text = text.strip()
#     for c in ",;:":
#         text = text.replace(c, ".")
#     text = remove_duplicated_punctuations(text)
#     text = jamo_text(text)
#     text = g2p.idioms(text)
#     text = g2pk.english.convert_eng(text, g2p.cmu)
#     text = g2pk.utils.annotate(text, g2p.mecab)
#     text = g2pk.numerals.convert_num(text)
#     text = re.sub("/[PJEB]", "", text)
#     text = alphabet_text(text)
#     text = normalize("NFD", text)
#     text = "".join(c for c in text if c in symbols)
#     text = normalize("NFC", text)
#     text = text.strip()
#     if len(text) == 0:
#         return ""
#     if text in '.!?':
#         return punctuation_text(text)
#     if text[-1] not in '.!?':
#         text += '.'
#     return text
# 
# def remove_duplicated_punctuations(text):
#     text = re.sub(r"[.?!]+\?", "?", text)
#     text = re.sub(r"[.?!]+!", "!", text)
#     text = re.sub(r"[.?!]+\.", ".", text)
#     return text
# 
# def split_text(text):
#     text = remove_duplicated_punctuations(text)
#     texts = []
#     for subtext in re.findall(r'[^.!?\n]*[.!?\n]', text):
#         texts.append(subtext.strip())
#     return texts
# 
# def alphabet_text(text):
#     text = re.sub(r"(a|A)", "에이", text)
#     text = re.sub(r"(b|B)", "비", text)
#     text = re.sub(r"(c|C)", "씨", text)
#     text = re.sub(r"(d|D)", "디", text)
#     text = re.sub(r"(e|E)", "이", text)
#     text = re.sub(r"(f|F)", "에프", text)
#     text = re.sub(r"(g|G)", "쥐", text)
#     text = re.sub(r"(h|H)", "에이치", text)
#     text = re.sub(r"(i|I)", "아이", text)
#     text = re.sub(r"(j|J)", "제이", text)
#     text = re.sub(r"(k|K)", "케이", text)
#     text = re.sub(r"(l|L)", "엘", text)
#     text = re.sub(r"(m|M)", "엠", text)
#     text = re.sub(r"(n|N)", "엔", text)
#     text = re.sub(r"(o|O)", "오", text)
#     text = re.sub(r"(p|P)", "피", text)
#     text = re.sub(r"(q|Q)", "큐", text)
#     text = re.sub(r"(r|R)", "알", text)
#     text = re.sub(r"(s|S)", "에스", text)
#     text = re.sub(r"(t|T)", "티", text)
#     text = re.sub(r"(u|U)", "유", text)
#     text = re.sub(r"(v|V)", "브이", text)
#     text = re.sub(r"(w|W)", "더블유", text)
#     text = re.sub(r"(x|X)", "엑스", text)
#     text = re.sub(r"(y|Y)", "와이", text)
#     text = re.sub(r"(z|Z)", "지", text)
#     return text
# 
# def punctuation_text(text):
#     text = re.sub(r"!", "느낌표", text)
#     text = re.sub(r"\?", "물음표", text)
#     text = re.sub(r"\.", "마침표", text)
#     return text
# 
# def jamo_text(text):
#     text = re.sub(r"ㄱ", "기역", text)
#     text = re.sub(r"ㄴ", "니은", text)
#     text = re.sub(r"ㄷ", "디귿", text)
#     text = re.sub(r"ㄹ", "리을", text)
#     text = re.sub(r"ㅁ", "미음", text)
#     text = re.sub(r"ㅂ", "비읍", text)
#     text = re.sub(r"ㅅ", "시옷", text)
#     text = re.sub(r"ㅇ", "이응", text)
#     text = re.sub(r"ㅈ", "지읒", text)
#     text = re.sub(r"ㅊ", "치읓", text)
#     text = re.sub(r"ㅋ", "키읔", text)
#     text = re.sub(r"ㅌ", "티읕", text)
#     text = re.sub(r"ㅍ", "피읖", text)
#     text = re.sub(r"ㅎ", "히읗", text)
#     text = re.sub(r"ㄲ", "쌍기역", text)
#     text = re.sub(r"ㄸ", "쌍디귿", text)
#     text = re.sub(r"ㅃ", "쌍비읍", text)
#     text = re.sub(r"ㅆ", "쌍시옷", text)
#     text = re.sub(r"ㅉ", "쌍지읒", text)
#     text = re.sub(r"ㄳ", "기역시옷", text)
#     text = re.sub(r"ㄵ", "니은지읒", text)
#     text = re.sub(r"ㄶ", "니은히읗", text)
#     text = re.sub(r"ㄺ", "리을기역", text)
#     text = re.sub(r"ㄻ", "리을미음", text)
#     text = re.sub(r"ㄼ", "리을비읍", text)
#     text = re.sub(r"ㄽ", "리을시옷", text)
#     text = re.sub(r"ㄾ", "리을티읕", text)
#     text = re.sub(r"ㄿ", "리을피읍", text)
#     text = re.sub(r"ㅀ", "리을히읗", text)
#     text = re.sub(r"ㅄ", "비읍시옷", text)
#     text = re.sub(r"ㅏ", "아", text)
#     text = re.sub(r"ㅑ", "야", text)
#     text = re.sub(r"ㅓ", "어", text)
#     text = re.sub(r"ㅕ", "여", text)
#     text = re.sub(r"ㅗ", "오", text)
#     text = re.sub(r"ㅛ", "요", text)
#     text = re.sub(r"ㅜ", "우", text)
#     text = re.sub(r"ㅠ", "유", text)
#     text = re.sub(r"ㅡ", "으", text)
#     text = re.sub(r"ㅣ", "이", text)
#     text = re.sub(r"ㅐ", "애", text)
#     text = re.sub(r"ㅒ", "얘", text)
#     text = re.sub(r"ㅔ", "에", text)
#     text = re.sub(r"ㅖ", "예", text)
#     text = re.sub(r"ㅘ", "와", text)
#     text = re.sub(r"ㅙ", "왜", text)
#     text = re.sub(r"ㅚ", "외", text)
#     text = re.sub(r"ㅝ", "워", text)
#     text = re.sub(r"ㅞ", "웨", text)
#     text = re.sub(r"ㅟ", "위", text)
#     text = re.sub(r"ㅢ", "의", text)
#     return text
# 
# def normalize_multiline_text(long_text):
#     texts = split_text(long_text)
#     normalized_texts = [normalize_text(text).strip() for text in texts]
#     return [text for text in normalized_texts if len(text) > 0]
# 
# def synthesize(text):
#     global synthesizer
#     wavs = synthesizer.tts(text, None, None)
#     return wavs
# 
# if __name__ == "__main__":
#     synthesizer = initialize_synthesizer()
#     text = "안녕하세요. SCE-TTS를 사용해 음성을 합성합니다!"
#     normalized_texts = normalize_multiline_text(text)
#     for norm_text in normalized_texts:
#         print(f"Normalized text: {norm_text}")
#         wav = synthesize(norm_text)
#         # Colab에서 오디오 출력을 위해 파일로 저장
#         import soundfile as sf
#         sf.write(f"/content/output_{norm_text[:10]}.wav", wav, synthesizer.tts_config.audio["sample_rate"])

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/TTS

# soundfile 설치
!/content/tts_env/bin/pip install soundfile

# synthesize.py 파일 생성 (%%writefile 대신 Python으로 파일 작성)
code = """
import re
import sys
from unicodedata import normalize
from TTS.utils.synthesizer import Synthesizer
from TTS.tts.configs.glow_tts_config import GlowTTSConfig
from TTS.vocoder.configs.hifigan_config import HifiganConfig
import g2pk

# symbols 정의
from TTS.tts.utils.text.symbols import symbols

# Synthesizer 초기화
def initialize_synthesizer():
    tts_checkpoint = "/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/best_model.pth.tar"
    tts_config_path = "/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/config.json"
    vocoder_checkpoint = "/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/model_file.pth.tar"
    vocoder_config_path = "/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/config.json"

    synthesizer = Synthesizer(
        tts_checkpoint=tts_checkpoint,
        tts_config_path=tts_config_path,
        vocoder_checkpoint=vocoder_checkpoint,
        vocoder_config_path=vocoder_config_path
    )
    return synthesizer

# g2pK 초기화
g2p = g2pk.G2p()

def normalize_text(text):
    text = text.strip()
    for c in ",;:":
        text = text.replace(c, ".")
    text = remove_duplicated_punctuations(text)
    text = jamo_text(text)
    text = g2p.idioms(text)
    text = g2pk.english.convert_eng(text, g2p.cmu)
    text = g2pk.utils.annotate(text, g2p.mecab)
    text = g2pk.numerals.convert_num(text)
    text = re.sub("/[PJEB]", "", text)
    text = alphabet_text(text)
    text = normalize("NFD", text)
    text = "".join(c for c in text if c in symbols)
    text = normalize("NFC", text)
    text = text.strip()
    if len(text) == 0:
        return ""
    if text in '.!?':
        return punctuation_text(text)
    if text[-1] not in '.!?':
        text += '.'
    return text

def remove_duplicated_punctuations(text):
    text = re.sub(r"[.?!]+\?", "?", text)
    text = re.sub(r"[.?!]+!", "!", text)
    text = re.sub(r"[.?!]+\.", ".", text)
    return text

def split_text(text):
    text = remove_duplicated_punctuations(text)
    texts = []
    for subtext in re.findall(r'[^.!?\n]*[.!?\n]', text):
        texts.append(subtext.strip())
    return texts

def alphabet_text(text):
    text = re.sub(r"(a|A)", "에이", text)
    text = re.sub(r"(b|B)", "비", text)
    text = re.sub(r"(c|C)", "씨", text)
    text = re.sub(r"(d|D)", "디", text)
    text = re.sub(r"(e|E)", "이", text)
    text = re.sub(r"(f|F)", "에프", text)
    text = re.sub(r"(g|G)", "쥐", text)
    text = re.sub(r"(h|H)", "에이치", text)
    text = re.sub(r"(i|I)", "아이", text)
    text = re.sub(r"(j|J)", "제이", text)
    text = re.sub(r"(k|K)", "케이", text)
    text = re.sub(r"(l|L)", "엘", text)
    text = re.sub(r"(m|M)", "엠", text)
    text = re.sub(r"(n|N)", "엔", text)
    text = re.sub(r"(o|O)", "오", text)
    text = re.sub(r"(p|P)", "피", text)
    text = re.sub(r"(q|Q)", "큐", text)
    text = re.sub(r"(r|R)", "알", text)
    text = re.sub(r"(s|S)", "에스", text)
    text = re.sub(r"(t|T)", "티", text)
    text = re.sub(r"(u|U)", "유", text)
    text = re.sub(r"(v|V)", "브이", text)
    text = re.sub(r"(w|W)", "더블유", text)
    text = re.sub(r"(x|X)", "엑스", text)
    text = re.sub(r"(y|Y)", "와이", text)
    text = re.sub(r"(z|Z)", "지", text)
    return text

def punctuation_text(text):
    text = re.sub(r"!", "느낌표", text)
    text = re.sub(r"\?", "물음표", text)
    text = re.sub(r"\.", "마침표", text)
    return text

def jamo_text(text):
    text = re.sub(r"ㄱ", "기역", text)
    text = re.sub(r"ㄴ", "니은", text)
    text = re.sub(r"ㄷ", "디귿", text)
    text = re.sub(r"ㄹ", "리을", text)
    text = re.sub(r"ㅁ", "미음", text)
    text = re.sub(r"ㅂ", "비읍", text)
    text = re.sub(r"ㅅ", "시옷", text)
    text = re.sub(r"ㅇ", "이응", text)
    text = re.sub(r"ㅈ", "지읒", text)
    text = re.sub(r"ㅊ", "치읓", text)
    text = re.sub(r"ㅋ", "키읔", text)
    text = re.sub(r"ㅌ", "티읕", text)
    text = re.sub(r"ㅍ", "피읖", text)
    text = re.sub(r"ㅎ", "히읗", text)
    text = re.sub(r"ㄲ", "쌍기역", text)
    text = re.sub(r"ㄸ", "쌍디귿", text)
    text = re.sub(r"ㅃ", "쌍비읍", text)
    text = re.sub(r"ㅆ", "쌍시옷", text)
    text = re.sub(r"ㅉ", "쌍지읒", text)
    text = re.sub(r"ㄳ", "기역시옷", text)
    text = re.sub(r"ㄵ", "니은지읒", text)
    text = re.sub(r"ㄶ", "니은히읗", text)
    text = re.sub(r"ㄺ", "리을기역", text)
    text = re.sub(r"ㄻ", "리을미음", text)
    text = re.sub(r"ㄼ", "리을비읍", text)
    text = re.sub(r"ㄽ", "리을시옷", text)
    text = re.sub(r"ㄾ", "리을티읕", text)
    text = re.sub(r"ㄿ", "리을피읍", text)
    text = re.sub(r"ㅀ", "리을히읗", text)
    text = re.sub(r"ㅄ", "비읍시옷", text)
    text = re.sub(r"ㅏ", "아", text)
    text = re.sub(r"ㅑ", "야", text)
    text = re.sub(r"ㅓ", "어", text)
    text = re.sub(r"ㅕ", "여", text)
    text = re.sub(r"ㅗ", "오", text)
    text = re.sub(r"ㅛ", "요", text)
    text = re.sub(r"ㅜ", "우", text)
    text = re.sub(r"ㅠ", "유", text)
    text = re.sub(r"ㅡ", "으", text)
    text = re.sub(r"ㅣ", "이", text)
    text = re.sub(r"ㅐ", "애", text)
    text = re.sub(r"ㅒ", "얘", text)
    text = re.sub(r"ㅔ", "에", text)
    text = re.sub(r"ㅖ", "예", text)
    text = re.sub(r"ㅘ", "와", text)
    text = re.sub(r"ㅙ", "왜", text)
    text = re.sub(r"ㅚ", "외", text)
    text = re.sub(r"ㅝ", "워", text)
    text = re.sub(r"ㅞ", "웨", text)
    text = re.sub(r"ㅟ", "위", text)
    text = re.sub(r"ㅢ", "의", text)
    return text

def normalize_multiline_text(long_text):
    texts = split_text(long_text)
    normalized_texts = [normalize_text(text).strip() for text in texts]
    return [text for text in normalized_texts if len(text) > 0]

def synthesize(text):
    global synthesizer
    wavs = synthesizer.tts(text, None, None)
    return wavs

if __name__ == "__main__":
    synthesizer = initialize_synthesizer()
    text = "안녕하세요. SCE-TTS를 사용해 음성을 합성합니다!"
    normalized_texts = normalize_multiline_text(text)
    for norm_text in normalized_texts:
        print(f"Normalized text: {norm_text}")
        wav = synthesize(norm_text)
        import soundfile as sf
        sf.write(f"/content/output_{norm_text[:10]}.wav", wav, synthesizer.tts_config.audio["sample_rate"])
"""

with open("synthesize.py", "w") as f:
    f.write(code)

# Python 버전 및 모듈 확인
!/content/tts_env/bin/python --version
!/content/tts_env/bin/python -c "import TTS; print(TTS.__version__)"
!/content/tts_env/bin/python -c "import pysbd; print(pysbd.__version__)"
!/content/tts_env/bin/python -c "import g2pk; print(g2pk.__version__)"

# TTS 재설치
!/content/tts_env/bin/pip install -q --no-cache-dir -e .

# 스크립트 실행
!/content/tts_env/bin/python synthesize.py

# 생성된 오디오 파일 확인 및 재생
!ls /content/*.wav
from IPython.display import Audio, display
import glob
for wav_file in glob.glob("/content/*.wav"):
    display(Audio(wav_file))

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/TTS

# soundfile 설치
!/content/tts_env/bin/pip install soundfile

# synthesize.py 파일 생성
code = """
import re
import sys
from unicodedata import normalize
from TTS.utils.synthesizer import Synthesizer
import g2pk

# symbols 정의
from TTS.tts.utils.text.symbols import symbols

# Synthesizer 초기화
def initialize_synthesizer():
    tts_checkpoint = "/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/best_model.pth.tar"
    tts_config_path = "/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/config.json"
    vocoder_checkpoint = "/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/model_file.pth.tar"
    vocoder_config_path = "/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/config.json"

    synthesizer = Synthesizer(
        tts_checkpoint=tts_checkpoint,
        tts_config_path=tts_config_path,
        vocoder_checkpoint=vocoder_checkpoint,
        vocoder_config_path=vocoder_config_path
    )
    return synthesizer

# g2pK 초기화
g2p = g2pk.G2p()

def normalize_text(text):
    text = text.strip()
    for c in ",;:":
        text = text.replace(c, ".")
    text = remove_duplicated_punctuations(text)
    text = jamo_text(text)
    text = g2p.idioms(text)
    text = g2pk.english.convert_eng(text, g2p.cmu)
    text = g2pk.utils.annotate(text, g2p.mecab)
    text = g2pk.numerals.convert_num(text)
    text = re.sub("/[PJEB]", "", text)
    text = alphabet_text(text)
    text = normalize("NFD", text)
    text = "".join(c for c in text if c in symbols)
    text = normalize("NFC", text)
    text = text.strip()
    if len(text) == 0:
        return ""
    if text in '.!?':
        return punctuation_text(text)
    if text[-1] not in '.!?':
        text += '.'
    return text

def remove_duplicated_punctuations(text):
    text = re.sub(r"[.?!]+\?", "?", text)
    text = re.sub(r"[.?!]+!", "!", text)
    text = re.sub(r"[.?!]+\.", ".", text)
    return text

def split_text(text):
    text = remove_duplicated_punctuations(text)
    texts = []
    for subtext in re.findall(r'[^.!?\\n]*[.!?\\n]', text):
        texts.append(subtext.strip())
    return texts

def alphabet_text(text):
    text = re.sub(r"(a|A)", "에이", text)
    text = re.sub(r"(b|B)", "비", text)
    text = re.sub(r"(c|C)", "씨", text)
    text = re.sub(r"(d|D)", "디", text)
    text = re.sub(r"(e|E)", "이", text)
    text = re.sub(r"(f|F)", "에프", text)
    text = re.sub(r"(g|G)", "쥐", text)
    text = re.sub(r"(h|H)", "에이치", text)
    text = re.sub(r"(i|I)", "아이", text)
    text = re.sub(r"(j|J)", "제이", text)
    text = re.sub(r"(k|K)", "케이", text)
    text = re.sub(r"(l|L)", "엘", text)
    text = re.sub(r"(m|M)", "엠", text)
    text = re.sub(r"(n|N)", "엔", text)
    text = re.sub(r"(o|O)", "오", text)
    text = re.sub(r"(p|P)", "피", text)
    text = re.sub(r"(q|Q)", "큐", text)
    text = re.sub(r"(r|R)", "알", text)
    text = re.sub(r"(s|S)", "에스", text)
    text = re.sub(r"(t|T)", "티", text)
    text = re.sub(r"(u|U)", "유", text)
    text = re.sub(r"(v|V)", "브이", text)
    text = re.sub(r"(w|W)", "더블유", text)
    text = re.sub(r"(x|X)", "엑스", text)
    text = re.sub(r"(y|Y)", "와이", text)
    text = re.sub(r"(z|Z)", "지", text)
    return text

def punctuation_text(text):
    text = re.sub(r"!", "느낌표", text)
    text = re.sub(r"\?", "물음표", text)
    text = re.sub(r"\.", "마침표", text)
    return text

def jamo_text(text):
    text = re.sub(r"ㄱ", "기역", text)
    text = re.sub(r"ㄴ", "니은", text)
    text = re.sub(r"ㄷ", "디귿", text)
    text = re.sub(r"ㄹ", "리을", text)
    text = re.sub(r"ㅁ", "미음", text)
    text = re.sub(r"ㅂ", "비읍", text)
    text = re.sub(r"ㅅ", "시옷", text)
    text = re.sub(r"ㅇ", "이응", text)
    text = re.sub(r"ㅈ", "지읒", text)
    text = re.sub(r"ㅊ", "치읓", text)
    text = re.sub(r"ㅋ", "키읔", text)
    text = re.sub(r"ㅌ", "티읕", text)
    text = re.sub(r"ㅍ", "피읖", text)
    text = re.sub(r"ㅎ", "히읗", text)
    text = re.sub(r"ㄲ", "쌍기역", text)
    text = re.sub(r"ㄸ", "쌍디귿", text)
    text = re.sub(r"ㅃ", "쌍비읍", text)
    text = re.sub(r"ㅆ", "쌍시옷", text)
    text = re.sub(r"ㅉ", "쌍지읒", text)
    text = re.sub(r"ㄳ", "기역시옷", text)
    text = re.sub(r"ㄵ", "니은지읒", text)
    text = re.sub(r"ㄶ", "니은히읗", text)
    text = re.sub(r"ㄺ", "리을기역", text)
    text = re.sub(r"ㄻ", "리을미음", text)
    text = re.sub(r"ㄼ", "리을비읍", text)
    text = re.sub(r"ㄽ", "리을시옷", text)
    text = re.sub(r"ㄾ", "리을티읕", text)
    text = re.sub(r"ㄿ", "리을피읍", text)
    text = re.sub(r"ㅀ", "리을히읗", text)
    text = re.sub(r"ㅄ", "비읍시옷", text)
    text = re.sub(r"ㅏ", "아", text)
    text = re.sub(r"ㅑ", "야", text)
    text = re.sub(r"ㅓ", "어", text)
    text = re.sub(r"ㅕ", "여", text)
    text = re.sub(r"ㅗ", "오", text)
    text = re.sub(r"ㅛ", "요", text)
    text = re.sub(r"ㅜ", "우", text)
    text = re.sub(r"ㅠ", "유", text)
    text = re.sub(r"ㅡ", "으", text)
    text = re.sub(r"ㅣ", "이", text)
    text = re.sub(r"ㅐ", "애", text)
    text = re.sub(r"ㅒ", "얘", text)
    text = re.sub(r"ㅔ", "에", text)
    text = re.sub(r"ㅖ", "예", text)
    text = re.sub(r"ㅘ", "와", text)
    text = re.sub(r"ㅙ", "왜", text)
    text = re.sub(r"ㅚ", "외", text)
    text = re.sub(r"ㅝ", "워", text)
    text = re.sub(r"ㅞ", "웨", text)
    text = re.sub(r"ㅟ", "위", text)
    text = re.sub(r"ㅢ", "의", text)
    return text

def normalize_multiline_text(long_text):
    texts = split_text(long_text)
    normalized_texts = [normalize_text(text).strip() for text in texts]
    return [text for text in normalized_texts if len(text) > 0]

def synthesize(text):
    global synthesizer
    wavs = synthesizer.tts(text, None, None)
    return wavs

if __name__ == "__main__":
    synthesizer = initialize_synthesizer()
    text = "안녕하세요. SCE-TTS를 사용해 음성을 합성합니다!"
    normalized_texts = normalize_multiline_text(text)
    for norm_text in normalized_texts:
        print(f"Normalized text: {norm_text}")
        wav = synthesize(norm_text)
        import soundfile as sf
        sf.write(f"/content/output_{norm_text[:10]}.wav", wav, synthesizer.tts_config.audio["sample_rate"])
"""

with open("synthesize.py", "w") as f:
    f.write(code)

# Python 버전 및 모듈 확인
!/content/tts_env/bin/python --version
!/content/tts_env/bin/python -c "import TTS; print(TTS.__version__)"
!/content/tts_env/bin/python -c "import pysbd; print(pysbd.__version__)"
!/content/tts_env/bin/python -c "import g2pk; print('g2pk installed')"

# TTS 재설치
!/content/tts_env/bin/pip install -q --no-cache-dir -e .

# 스크립트 실행
!/content/tts_env/bin/python synthesize.py

# 생성된 오디오 파일 확인 및 재생
!ls /content/*.wav
from IPython.display import Audio, display
import glob
for wav_file in glob.glob("/content/*.wav"):
    display(Audio(wav_file))

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/TTS
import re
import sys
from unicodedata import normalize
import IPython

from TTS.utils.synthesizer import Synthesizer

def normalize_text(text):
    text = text.strip()

    for c in ",;:":
        text = text.replace(c, ".")
    text = remove_duplicated_punctuations(text)

    text = jamo_text(text)

    text = g2p.idioms(text)
    text = g2pk.english.convert_eng(text, g2p.cmu)
    text = g2pk.utils.annotate(text, g2p.mecab)
    text = g2pk.numerals.convert_num(text)
    text = re.sub("/[PJEB]", "", text)

    text = alphabet_text(text)

    # remove unreadable characters
    text = normalize("NFD", text)
    text = "".join(c for c in text if c in symbols)
    text = normalize("NFC", text)

    text = text.strip()
    if len(text) == 0:
        return ""

    # only single punctuation
    if text in '.!?':
        return punctuation_text(text)

    # append punctuation if there is no punctuation at the end of the text
    if text[-1] not in '.!?':
        text += '.'

    return text


def remove_duplicated_punctuations(text):
    text = re.sub(r"[.?!]+\?", "?", text)
    text = re.sub(r"[.?!]+!", "!", text)
    text = re.sub(r"[.?!]+\.", ".", text)
    return text


def split_text(text):
    text = remove_duplicated_punctuations(text)

    texts = []
    for subtext in re.findall(r'[^.!?\n]*[.!?\n]', text):
        texts.append(subtext.strip())

    return texts


def alphabet_text(text):
    text = re.sub(r"(a|A)", "에이", text)
    text = re.sub(r"(b|B)", "비", text)
    text = re.sub(r"(c|C)", "씨", text)
    text = re.sub(r"(d|D)", "디", text)
    text = re.sub(r"(e|E)", "이", text)
    text = re.sub(r"(f|F)", "에프", text)
    text = re.sub(r"(g|G)", "쥐", text)
    text = re.sub(r"(h|H)", "에이치", text)
    text = re.sub(r"(i|I)", "아이", text)
    text = re.sub(r"(j|J)", "제이", text)
    text = re.sub(r"(k|K)", "케이", text)
    text = re.sub(r"(l|L)", "엘", text)
    text = re.sub(r"(m|M)", "엠", text)
    text = re.sub(r"(n|N)", "엔", text)
    text = re.sub(r"(o|O)", "오", text)
    text = re.sub(r"(p|P)", "피", text)
    text = re.sub(r"(q|Q)", "큐", text)
    text = re.sub(r"(r|R)", "알", text)
    text = re.sub(r"(s|S)", "에스", text)
    text = re.sub(r"(t|T)", "티", text)
    text = re.sub(r"(u|U)", "유", text)
    text = re.sub(r"(v|V)", "브이", text)
    text = re.sub(r"(w|W)", "더블유", text)
    text = re.sub(r"(x|X)", "엑스", text)
    text = re.sub(r"(y|Y)", "와이", text)
    text = re.sub(r"(z|Z)", "지", text)

    return text


def punctuation_text(text):
    # 문장부호
    text = re.sub(r"!", "느낌표", text)
    text = re.sub(r"\?", "물음표", text)
    text = re.sub(r"\.", "마침표", text)

    return text


def jamo_text(text):
    # 기본 자모음
    text = re.sub(r"ㄱ", "기역", text)
    text = re.sub(r"ㄴ", "니은", text)
    text = re.sub(r"ㄷ", "디귿", text)
    text = re.sub(r"ㄹ", "리을", text)
    text = re.sub(r"ㅁ", "미음", text)
    text = re.sub(r"ㅂ", "비읍", text)
    text = re.sub(r"ㅅ", "시옷", text)
    text = re.sub(r"ㅇ", "이응", text)
    text = re.sub(r"ㅈ", "지읒", text)
    text = re.sub(r"ㅊ", "치읓", text)
    text = re.sub(r"ㅋ", "키읔", text)
    text = re.sub(r"ㅌ", "티읕", text)
    text = re.sub(r"ㅍ", "피읖", text)
    text = re.sub(r"ㅎ", "히읗", text)
    text = re.sub(r"ㄲ", "쌍기역", text)
    text = re.sub(r"ㄸ", "쌍디귿", text)
    text = re.sub(r"ㅃ", "쌍비읍", text)
    text = re.sub(r"ㅆ", "쌍시옷", text)
    text = re.sub(r"ㅉ", "쌍지읒", text)
    text = re.sub(r"ㄳ", "기역시옷", text)
    text = re.sub(r"ㄵ", "니은지읒", text)
    text = re.sub(r"ㄶ", "니은히읗", text)
    text = re.sub(r"ㄺ", "리을기역", text)
    text = re.sub(r"ㄻ", "리을미음", text)
    text = re.sub(r"ㄼ", "리을비읍", text)
    text = re.sub(r"ㄽ", "리을시옷", text)
    text = re.sub(r"ㄾ", "리을티읕", text)
    text = re.sub(r"ㄿ", "리을피읍", text)
    text = re.sub(r"ㅀ", "리을히읗", text)
    text = re.sub(r"ㅄ", "비읍시옷", text)
    text = re.sub(r"ㅏ", "아", text)
    text = re.sub(r"ㅑ", "야", text)
    text = re.sub(r"ㅓ", "어", text)
    text = re.sub(r"ㅕ", "여", text)
    text = re.sub(r"ㅗ", "오", text)
    text = re.sub(r"ㅛ", "요", text)
    text = re.sub(r"ㅜ", "우", text)
    text = re.sub(r"ㅠ", "유", text)
    text = re.sub(r"ㅡ", "으", text)
    text = re.sub(r"ㅣ", "이", text)
    text = re.sub(r"ㅐ", "애", text)
    text = re.sub(r"ㅒ", "얘", text)
    text = re.sub(r"ㅔ", "에", text)
    text = re.sub(r"ㅖ", "예", text)
    text = re.sub(r"ㅘ", "와", text)
    text = re.sub(r"ㅙ", "왜", text)
    text = re.sub(r"ㅚ", "외", text)
    text = re.sub(r"ㅝ", "워", text)
    text = re.sub(r"ㅞ", "웨", text)
    text = re.sub(r"ㅟ", "위", text)
    text = re.sub(r"ㅢ", "의", text)

    return text


def normalize_multiline_text(long_text):
    texts = split_text(long_text)
    normalized_texts = [normalize_text(text).strip() for text in texts]
    return [text for text in normalized_texts if len(text) > 0]

def synthesize(text):
    wavs = synthesizer.tts(text, None, None)
    return wavs

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/TTS

# Google Drive 마운트
from google.colab import drive
drive.mount('/content/drive')

# pysbd 및 soundfile 설치
!/content/tts_env/bin/pip install pysbd soundfile

# synthesize.py 파일 생성
code = """
import re
import sys
from unicodedata import normalize
from TTS.utils.synthesizer import Synthesizer
import g2pk

# symbols 정의
from TTS.tts.utils.text.symbols import symbols

# Synthesizer 초기화
def initialize_synthesizer():
    tts_checkpoint = "/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/best_model.pth.tar"
    tts_config_path = "/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/config.json"
    vocoder_checkpoint = "/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/model_file.pth.tar"
    vocoder_config_path = "/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/config.json"

    synthesizer = Synthesizer(
        tts_checkpoint=tts_checkpoint,
        tts_config_path=tts_config_path,
        tts_speakers_file=None,
        vocoder_checkpoint=vocoder_checkpoint,
        vocoder_config=vocoder_config_path,
        encoder_checkpoint=None,
        encoder_config=None,
        use_cuda=False
    )
    return synthesizer

# g2pK 초기화
g2p = g2pk.G2p()

def normalize_text(text):
    text = text.strip()
    for c in ",;:":
        text = text.replace(c, ".")
    text = remove_duplicated_punctuations(text)
    text = jamo_text(text)
    text = g2p.idioms(text)
    text = g2pk.english.convert_eng(text, g2p.cmu)
    text = g2pk.utils.annotate(text, g2p.mecab)
    text = g2pk.numerals.convert_num(text)
    text = re.sub("/[PJEB]", "", text)
    text = alphabet_text(text)
    text = normalize("NFD", text)
    text = "".join(c for c in text if c in symbols)
    text = normalize("NFC", text)
    text = text.strip()
    if len(text) == 0:
        return ""
    if text in '.!?':
        return punctuation_text(text)
    if text[-1] not in '.!?':
        text += '.'
    return text

def remove_duplicated_punctuations(text):
    text = re.sub(r"[.?!]+\?", "?", text)
    text = re.sub(r"[.?!]+!", "!", text)
    text = re.sub(r"[.?!]+\.", ".", text)
    return text

def split_text(text):
    text = remove_duplicated_punctuations(text)
    texts = []
    for subtext in re.findall(r'[^.!?\\n]*[.!?\\n]', text):
        texts.append(subtext.strip())
    return texts

def alphabet_text(text):
    text = re.sub(r"(a|A)", "에이", text)
    text = re.sub(r"(b|B)", "비", text)
    text = re.sub(r"(c|C)", "씨", text)
    text = re.sub(r"(d|D)", "디", text)
    text = re.sub(r"(e|E)", "이", text)
    text = re.sub(r"(f|F)", "에프", text)
    text = re.sub(r"(g|G)", "쥐", text)
    text = re.sub(r"(h|H)", "에이치", text)
    text = re.sub(r"(i|I)", "아이", text)
    text = re.sub(r"(j|J)", "제이", text)
    text = re.sub(r"(k|K)", "케이", text)
    text = re.sub(r"(l|L)", "엘", text)
    text = re.sub(r"(m|M)", "엠", text)
    text = re.sub(r"(n|N)", "엔", text)
    text = re.sub(r"(o|O)", "오", text)
    text = re.sub(r"(p|P)", "피", text)
    text = re.sub(r"(q|Q)", "큐", text)
    text = re.sub(r"(r|R)", "알", text)
    text = re.sub(r"(s|S)", "에스", text)
    text = re.sub(r"(t|T)", "티", text)
    text = re.sub(r"(u|U)", "유", text)
    text = re.sub(r"(v|V)", "브이", text)
    text = re.sub(r"(w|W)", "더블유", text)
    text = re.sub(r"(x|X)", "엑스", text)
    text = re.sub(r"(y|Y)", "와이", text)
    text = re.sub(r"(z|Z)", "지", text)
    return text

def punctuation_text(text):
    text = re.sub(r"!", "느낌표", text)
    text = re.sub(r"\?", "물음표", text)
    text = re.sub(r"\.", "마침표", text)
    return text

def jamo_text(text):
    text = re.sub(r"ㄱ", "기역", text)
    text = re.sub(r"ㄴ", "니은", text)
    text = re.sub(r"ㄷ", "디귿", text)
    text = re.sub(r"ㄹ", "리을", text)
    text = re.sub(r"ㅁ", "미음", text)
    text = re.sub(r"ㅂ", "비읍", text)
    text = re.sub(r"ㅅ", "시옷", text)
    text = re.sub(r"ㅇ", "이응", text)
    text = re.sub(r"ㅈ", "지읒", text)
    text = re.sub(r"ㅊ", "치읓", text)
    text = re.sub(r"ㅋ", "키읔", text)
    text = re.sub(r"ㅌ", "티읕", text)
    text = re.sub(r"ㅍ", "피읖", text)
    text = re.sub(r"ㅎ", "히읗", text)
    text = re.sub(r"ㄲ", "쌍기역", text)
    text = re.sub(r"ㄸ", "쌍디귿", text)
    text = re.sub(r"ㅃ", "쌍비읍", text)
    text = re.sub(r"ㅆ", "쌍시옷", text)
    text = re.sub(r"ㅉ", "쌍지읒", text)
    text = re.sub(r"ㄳ", "기역시옷", text)
    text = re.sub(r"ㄵ", "니은지읒", text)
    text = re.sub(r"ㄶ", "니은히읗", text)
    text = re.sub(r"ㄺ", "리을기역", text)
    text = re.sub(r"ㄻ", "리을미음", text)
    text = re.sub(r"ㄼ", "리을비읍", text)
    text = re.sub(r"ㄽ", "리을시옷", text)
    text = re.sub(r"ㄾ", "리을티읕", text)
    text = re.sub(r"ㄿ", "리을피읍", text)
    text = re.sub(r"ㅀ", "리을히읗", text)
    text = re.sub(r"ㅄ", "비읍시옷", text)
    text = re.sub(r"ㅏ", "아", text)
    text = re.sub(r"ㅑ", "야", text)
    text = re.sub(r"ㅓ", "어", text)
    text = re.sub(r"ㅕ", "여", text)
    text = re.sub(r"ㅗ", "오", text)
    text = re.sub(r"ㅛ", "요", text)
    text = re.sub(r"ㅜ", "우", text)
    text = re.sub(r"ㅠ", "유", text)
    text = re.sub(r"ㅡ", "으", text)
    text = re.sub(r"ㅣ", "이", text)
    text = re.sub(r"ㅐ", "애", text)
    text = re.sub(r"ㅒ", "얘", text)
    text = re.sub(r"ㅔ", "에", text)
    text = re.sub(r"ㅖ", "예", text)
    text = re.sub(r"ㅘ", "와", text)
    text = re.sub(r"ㅙ", "왜", text)
    text = re.sub(r"ㅚ", "외", text)
    text = re.sub(r"ㅝ", "워", text)
    text = re.sub(r"ㅞ", "웨", text)
    text = re.sub(r"ㅟ", "위", text)
    text = re.sub(r"ㅢ", "의", text)
    return text

def normalize_multiline_text(long_text):
    texts = split_text(long_text)
    normalized_texts = [normalize_text(text).strip() for text in texts]
    return [text for text in normalized_texts if len(text) > 0]

def synthesize(text):
    global synthesizer
    wavs = synthesizer.tts(text, None, None)
    return wavs

if __name__ == "__main__":
    synthesizer = initialize_synthesizer()
    texts = '''
    아래 문장들은 모델 학습을 위해 사용하지 않은 문장들입니다.
    서울특별시 특허허가과 허가과장 허과장.
    경찰청 철창살은 외철창살이고 검찰청 철창살은 쌍철창살이다.
    지향을 지양으로 오기하는 일을 지양하는 언어 습관을 지향해야 한다.
    그러니까 외계인이 우리 생각을 읽고 우리 생각을 우리가 다시 생각토록 해서 그 생각이 마치 우리가 생각한 것인 것처럼 속였다는 거냐?
    안 촉촉한 초코칩 나라에 살던 안 촉촉한 초코칩이 촉촉한 초코칩 나라의 촉촉한 초코칩을 보고 촉촉한 초코칩이 되고 싶어서 촉촉한 초코칩 나라에 갔는데 촉촉한 초코칩 나라의 촉촉한 문지기가 넌 촉촉한 초코칩이 아니고 안 촉촉한 초코칩이니까 안 촉촉한 초코칩 나라에서 살라고 해서 안 촉촉한 초코칩은 촉촉한 초코칩이 되는 것을 포기하고 안 촉촉한 눈물을 흘리며 안 촉촉한 초코칩 나라로 돌아갔다.
    '''
    for i, text in enumerate(normalize_multiline_text(texts)):
        print(f"Normalized text: {text}")
        wav = synthesize(text)
        import soundfile as sf
        sf.write(f"/content/output_{i}.wav", wav, synthesizer.tts_config.audio["sample_rate"])
"""

with open("synthesize.py", "w") as f:
    f.write(code)

# Python 버전 및 모듈 확인
!/content/tts_env/bin/python --version
!/content/tts_env/bin/python -c "import TTS; print(TTS.__version__)"
!/content/tts_env/bin/python -c "import pysbd; print(pysbd.__version__)"
!/content/tts_env/bin/python -c "import g2pk; print('g2pk installed')"

# TTS 재설치
!/content/tts_env/bin/pip install -q --no-cache-dir -e .

# 스크립트 실행
!/content/tts_env/bin/python synthesize.py

# 생성된 오디오 파일 확인 및 재생
!ls /content/*.wav
from IPython.display import Audio, display
import glob
for wav_file in glob.glob("/content/*.wav"):
    display(Audio(wav_file))

"""## 3. 학습한 모델 불러오기

학습한 Glow-TTS와 HiFi-GAN 모델을 불러옵니다.

만약 다른 체크포인트에서 불러오시려면 아래 코드에서 경로를 아래와 같이 적절하게 수정합니다.

```python
synthesizer = Synthesizer(
    "/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-May-31-2021_08+17AM-d897f2e/best_model.pth.tar",
    "/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-May-31-2021_08+17AM-d897f2e/config.json",
    None,
    "/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-May-31-2021_08+26AM-d897f2e/checkpoint_300000.pth.tar",
    "/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-May-31-2021_08+26AM-d897f2e/config.json",
    None,
    None,
    False,
)
```
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/TTS

# run_synthesizer.py 파일 생성
code = """
from TTS.utils.synthesizer import Synthesizer

# Synthesizer 초기화
synthesizer = Synthesizer(
    tts_checkpoint="/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/best_model.pth.tar",
    tts_config_path="/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/config.json",
    tts_speakers_file=None,
    vocoder_checkpoint="/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/best_model_293026.pth.tar",
    vocoder_config="/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/config.json",
    encoder_checkpoint=None,
    encoder_config=None,
    use_cuda=False,
)

# symbols 추출
symbols = synthesizer.tts_config.characters.characters

# 결과 출력
print("Symbols:", symbols)
"""

with open("run_synthesizer.py", "w") as f:
    f.write(code)

# 스크립트 실행
!/content/tts_env/bin/python run_synthesizer.py

synthesizer = Synthesizer(
    "/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/model_file.pth.tar",
    "/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/config.json",
    None,
    "/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/best_model_293026.pth.tar",
    "/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/config.json",
    None,
    None,
    False,
)
symbols = synthesizer.tts_config.characters.characters

"""## 4. 음성 합성

실제 음성 합성을 수행합니다.

`long_text`의 값을 변경하여 다른 문장의 합성도 시도해보실 수 있습니다.
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/TTS

# synthesize_text.py 파일 생성
code = """
import re
import sys
from unicodedata import normalize
from TTS.utils.synthesizer import Synthesizer
import g2pk

# symbols 정의
from TTS.tts.utils.text.symbols import symbols

# Synthesizer 초기화
def initialize_synthesizer():
    synthesizer = Synthesizer(
        tts_checkpoint="/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/best_model.pth.tar",
        tts_config_path="/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/config.json",
        tts_speakers_file=None,
        vocoder_checkpoint="/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/best_model_293026.pth.tar",
        vocoder_config="/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/config.json",
        encoder_checkpoint=None,
        encoder_config=None,
        use_cuda=False,
    )
    return synthesizer

# g2pK 초기화
g2p = g2pk.G2p()

def normalize_text(text):
    text = text.strip()
    for c in ",;:":
        text = text.replace(c, ".")
    text = remove_duplicated_punctuations(text)
    text = jamo_text(text)
    text = g2p.idioms(text)
    text = g2pk.english.convert_eng(text, g2p.cmu)
    text = g2pk.utils.annotate(text, g2p.mecab)
    text = g2pk.numerals.convert_num(text)
    text = re.sub("/[PJEB]", "", text)
    text = alphabet_text(text)
    text = normalize("NFD", text)
    text = "".join(c for c in text if c in symbols)
    text = normalize("NFC", text)
    text = text.strip()
    if len(text) == 0:
        return ""
    if text in '.!?':
        return punctuation_text(text)
    if text[-1] not in '.!?':
        text += '.'
    return text

def remove_duplicated_punctuations(text):
    text = re.sub(r"[.?!]+\?", "?", text)
    text = re.sub(r"[.?!]+!", "!", text)
    text = re.sub(r"[.?!]+\.", ".", text)
    return text

def split_text(text):
    text = remove_duplicated_punctuations(text)
    texts = []
    for subtext in re.findall(r'[^.!?\\n]*[.!?\\n]', text):
        texts.append(subtext.strip())
    return texts

def alphabet_text(text):
    text = re.sub(r"(a|A)", "에이", text)
    text = re.sub(r"(b|B)", "비", text)
    text = re.sub(r"(c|C)", "씨", text)
    text = re.sub(r"(d|D)", "디", text)
    text = re.sub(r"(e|E)", "이", text)
    text = re.sub(r"(f|F)", "에프", text)
    text = re.sub(r"(g|G)", "쥐", text)
    text = re.sub(r"(h|H)", "에이치", text)
    text = re.sub(r"(i|I)", "아이", text)
    text = re.sub(r"(j|J)", "제이", text)
    text = re.sub(r"(k|K)", "케이", text)
    text = re.sub(r"(l|L)", "엘", text)
    text = re.sub(r"(m|M)", "엠", text)
    text = re.sub(r"(n|N)", "엔", text)
    text = re.sub(r"(o|O)", "오", text)
    text = re.sub(r"(p|P)", "피", text)
    text = re.sub(r"(q|Q)", "큐", text)
    text = re.sub(r"(r|R)", "알", text)
    text = re.sub(r"(s|S)", "에스", text)
    text = re.sub(r"(t|T)", "티", text)
    text = re.sub(r"(u|U)", "유", text)
    text = re.sub(r"(v|V)", "브이", text)
    text = re.sub(r"(w|W)", "더블유", text)
    text = re.sub(r"(x|X)", "엑스", text)
    text = re.sub(r"(y|Y)", "와이", text)
    text = re.sub(r"(z|Z)", "지", text)
    return text

def punctuation_text(text):
    text = re.sub(r"!", "느낌표", text)
    text = re.sub(r"\?", "물음표", text)
    text = re.sub(r"\.", "마침표", text)
    return text

def jamo_text(text):
    text = re.sub(r"ㄱ", "기역", text)
    text = re.sub(r"ㄴ", "니은", text)
    text = re.sub(r"ㄷ", "디귿", text)
    text = re.sub(r"ㄹ", "리을", text)
    text = re.sub(r"ㅁ", "미음", text)
    text = re.sub(r"ㅂ", "비읍", text)
    text = re.sub(r"ㅅ", "시옷", text)
    text = re.sub(r"ㅇ", "이응", text)
    text = re.sub(r"ㅈ", "지읒", text)
    text = re.sub(r"ㅊ", "치읓", text)
    text = re.sub(r"ㅋ", "키읔", text)
    text = re.sub(r"ㅌ", "티읕", text)
    text = re.sub(r"ㅍ", "피읖", text)
    text = re.sub(r"ㅎ", "히읗", text)
    text = re.sub(r"ㄲ", "쌍기역", text)
    text = re.sub(r"ㄸ", "쌍디귿", text)
    text = re.sub(r"ㅃ", "쌍비읍", text)
    text = re.sub(r"ㅆ", "쌍시옷", text)
    text = re.sub(r"ㅉ", "쌍지읒", text)
    text = re.sub(r"ㄳ", "기역시옷", text)
    text = re.sub(r"ㄵ", "니은지읒", text)
    text = re.sub(r"ㄶ", "니은히읗", text)
    text = re.sub(r"ㄺ", "리을기역", text)
    text = re.sub(r"ㄻ", "리을미음", text)
    text = re.sub(r"ㄼ", "리을비읍", text)
    text = re.sub(r"ㄽ", "리을시옷", text)
    text = re.sub(r"ㄾ", "리을티읕", text)
    text = re.sub(r"ㄿ", "리을피읍", text)
    text = re.sub(r"ㅀ", "리을히읗", text)
    text = re.sub(r"ㅄ", "비읍시옷", text)
    text = re.sub(r"ㅏ", "아", text)
    text = re.sub(r"ㅑ", "야", text)
    text = re.sub(r"ㅓ", "어", text)
    text = re.sub(r"ㅕ", "여", text)
    text = re.sub(r"ㅗ", "오", text)
    text = re.sub(r"ㅛ", "요", text)
    text = re.sub(r"ㅜ", "우", text)
    text = re.sub(r"ㅠ", "유", text)
    text = re.sub(r"ㅡ", "으", text)
    text = re.sub(r"ㅣ", "이", text)
    text = re.sub(r"ㅐ", "애", text)
    text = re.sub(r"ㅒ", "얘", text)
    text = re.sub(r"ㅔ", "에", text)
    text = re.sub(r"ㅖ", "예", text)
    text = re.sub(r"ㅘ", "와", text)
    text = re.sub(r"ㅙ", "왜", text)
    text = re.sub(r"ㅚ", "외", text)
    text = re.sub(r"ㅝ", "워", text)
    text = re.sub(r"ㅞ", "웨", text)
    text = re.sub(r"ㅟ", "위", text)
    text = re.sub(r"ㅢ", "의", text)
    return text

def normalize_multiline_text(long_text):
    texts = split_text(long_text)
    normalized_texts = [normalize_text(text).strip() for text in texts]
    return [text for text in normalized_texts if len(text) > 0]

def synthesize(text):
    global synthesizer
    wavs = synthesizer.tts(text, None, None)
    return wavs

if __name__ == "__main__":
    synthesizer = initialize_synthesizer()
    texts = '''
    아래 문장들은 모델 학습을 위해 사용하지 않은 문장들입니다.
    서울특별시 특허허가과 허가과장 허과장.
    경찰청 철창살은 외철창살이고 검찰청 철창살은 쌍철창살이다.
    지향을 지양으로 오기하는 일을 지양하는 언어 습관을 지향해야 한다.
    그러니까 외계인이 우리 생각을 읽고 우리 생각을 우리가 다시 생각토록 해서 그 생각이 마치 우리가 생각한 것인 것처럼 속였다는 거냐?
    안 촉촉한 초코칩 나라에 살던 안 촉촉한 초코칩이 촉촉한 초코칩 나라의 촉촉한 초코칩을 보고 촉촉한 초코칩이 되고 싶어서 촉촉한 초코칩 나라에 갔는데 촉촉한 초코칩 나라의 촉촉한 문지기가 넌 촉촉한 초코칩이 아니고 안 촉촉한 초코칩이니까 안 촉촉한 초코칩 나라에서 살라고 해서 안 촉촉한 초코칩은 촉촉한 초코칩이 되는 것을 포기하고 안 촉촉한 눈물을 흘리며 안 촉촉한 초코칩 나라로 돌아갔다.
    '''
    for i, text in enumerate(normalize_multiline_text(texts)):
        print(f"Processing text {i}: {text}")
        wav = synthesize(text)
        import soundfile as sf
        sf.write(f"/content/output_{i}.wav", wav, synthesizer.tts_config.audio["sample_rate"])
"""

with open("synthesize_text.py", "w") as f:
    f.write(code)

# 스크립트 실행
!/content/tts_env/bin/python synthesize_text.py

# 생성된 오디오 파일 확인 및 재생
!ls /content/*.wav
from IPython.display import Audio, display
import glob
for wav_file in glob.glob("/content/*.wav"):
    print(f"Playing: {wav_file}")
    display(Audio(wav_file))

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/TTS

# 기존 WAV 파일 삭제
!rm -f /content/output_*.wav


# synthesize_text.py 파일 생성
code = """
import re
import sys
from unicodedata import normalize
from TTS.utils.synthesizer import Synthesizer
import g2pk

# symbols 정의
from TTS.tts.utils.text.symbols import symbols

# Synthesizer 초기화
def initialize_synthesizer():
    synthesizer = Synthesizer(
        tts_checkpoint="/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/best_model.pth.tar",  # 수정된 경로
        tts_config_path="/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/config.json",
        tts_speakers_file=None,
        vocoder_checkpoint="/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/best_model_293026.pth.tar",
        vocoder_config="/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/config.json",
        encoder_checkpoint=None,
        encoder_config=None,
        use_cuda=False,
    )
    return synthesizer

# g2pK 초기화
g2p = g2pk.G2p()

def normalize_text(text):
    print(f"Original text: {text}")
    text = text.strip()
    for c in ",;:":
        text = text.replace(c, ".")
    text = remove_duplicated_punctuations(text)
    print(f"After punctuation: {text}")
    text = jamo_text(text)
    print(f"After jamo: {text}")
    text = g2p.idioms(text)
    print(f"After idioms: {text}")
    text = g2pk.english.convert_eng(text, g2p.cmu)
    print(f"After english: {text}")
    text = g2pk.utils.annotate(text, g2p.mecab)
    print(f"After annotate: {text}")
    text = g2pk.numerals.convert_num(text)
    print(f"After numerals: {text}")
    text = re.sub("/[PJEB]", "", text)
    print(f"After regex: {text}")
    text = alphabet_text(text)
    print(f"After alphabet: {text}")
    text = normalize("NFD", text)
    text = "".join(c for c in text if c in symbols)
    print(f"After symbols filter: {text}")
    text = normalize("NFC", text)
    text = text.strip()
    if len(text) == 0:
        print("Empty text, returning empty string")
        return ""
    if text in '.!?':
        print(f"Punctuation only, converting: {text}")
        return punctuation_text(text)
    if text[-1] not in '.!?':
        text += '.'
    print(f"Final normalized text: {text}")
    return text

def remove_duplicated_punctuations(text):
    text = re.sub(r"[.?!]+\?", "?", text)
    text = re.sub(r"[.?!]+!", "!", text)
    text = re.sub(r"[.?!]+\.", ".", text)
    return text

def split_text(text):
    text = remove_duplicated_punctuations(text)
    texts = []
    for subtext in re.findall(r'[^.!?\\n]*[.!?\\n]', text):
        texts.append(subtext.strip())
    return texts

def alphabet_text(text):
    text = re.sub(r"(a|A)", "에이", text)
    text = re.sub(r"(b|B)", "비", text)
    text = re.sub(r"(c|C)", "씨", text)
    text = re.sub(r"(d|D)", "디", text)
    text = re.sub(r"(e|E)", "이", text)
    text = re.sub(r"(f|F)", "에프", text)
    text = re.sub(r"(g|G)", "쥐", text)
    text = re.sub(r"(h|H)", "에이치", text)
    text = re.sub(r"(i|I)", "아이", text)
    text = re.sub(r"(j|J)", "제이", text)
    text = re.sub(r"(k|K)", "케이", text)
    text = re.sub(r"(l|L)", "엘", text)
    text = re.sub(r"(m|M)", "엠", text)
    text = re.sub(r"(n|N)", "엔", text)
    text = re.sub(r"(o|O)", "오", text)
    text = re.sub(r"(p|P)", "피", text)
    text = re.sub(r"(q|Q)", "큐", text)
    text = re.sub(r"(r|R)", "알", text)
    text = re.sub(r"(s|S)", "에스", text)
    text = re.sub(r"(t|T)", "티", text)
    text = re.sub(r"(u|U)", "유", text)
    text = re.sub(r"(v|V)", "브이", text)
    text = re.sub(r"(w|W)", "더블유", text)
    text = re.sub(r"(x|X)", "엑스", text)
    text = re.sub(r"(y|Y)", "와이", text)
    text = re.sub(r"(z|Z)", "지", text)
    return text

def punctuation_text(text):
    text = re.sub(r"!", "느낌표", text)
    text = re.sub(r"\?", "물음표", text)
    text = re.sub(r"\.", "마침표", text)
    return text

def jamo_text(text):
    text = re.sub(r"ㄱ", "기역", text)
    text = re.sub(r"ㄴ", "니은", text)
    text = re.sub(r"ㄷ", "디귿", text)
    text = re.sub(r"ㄹ", "리을", text)
    text = re.sub(r"ㅁ", "미음", text)
    text = re.sub(r"ㅂ", "비읍", text)
    text = re.sub(r"ㅅ", "시옷", text)
    text = re.sub(r"ㅇ", "이응", text)
    text = re.sub(r"ㅈ", "지읒", text)
    text = re.sub(r"ㅊ", "치읓", text)
    text = re.sub(r"ㅋ", "키읔", text)
    text = re.sub(r"ㅌ", "티읕", text)
    text = re.sub(r"ㅍ", "피읖", text)
    text = re.sub(r"ㅎ", "히읗", text)
    text = re.sub(r"ㄲ", "쌍기역", text)
    text = re.sub(r"ㄸ", "쌍디귿", text)
    text = re.sub(r"ㅃ", "쌍비읍", text)
    text = re.sub(r"ㅆ", "쌍시옷", text)
    text = re.sub(r"ㅉ", "쌍지읒", text)
    text = re.sub(r"ㄳ", "기역시옷", text)
    text = re.sub(r"ㄵ", "니은지읒", text)
    text = re.sub(r"ㄶ", "니은히읗", text)
    text = re.sub(r"ㄺ", "리을기역", text)
    text = re.sub(r"ㄻ", "리을미음", text)
    text = re.sub(r"ㄼ", "리을비읍", text)
    text = re.sub(r"ㄽ", "리을시옷", text)
    text = re.sub(r"ㄾ", "리을티읕", text)
    text = re.sub(r"ㄿ", "리을피읍", text)
    text = re.sub(r"ㅀ", "리을히읗", text)
    text = re.sub(r"ㅄ", "비읍시옷", text)
    text = re.sub(r"ㅏ", "아", text)
    text = re.sub(r"ㅑ", "야", text)
    text = re.sub(r"ㅓ", "어", text)
    text = re.sub(r"ㅕ", "여", text)
    text = re.sub(r"ㅗ", "오", text)
    text = re.sub(r"ㅛ", "요", text)
    text = re.sub(r"ㅜ", "우", text)
    text = re.sub(r"ㅠ", "유", text)
    text = re.sub(r"ㅡ", "으", text)
    text = re.sub(r"ㅣ", "이", text)
    text = re.sub(r"ㅐ", "애", text)
    text = re.sub(r"ㅒ", "얘", text)
    text = re.sub(r"ㅔ", "에", text)
    text = re.sub(r"ㅖ", "예", text)
    text = re.sub(r"ㅘ", "와", text)
    text = re.sub(r"ㅙ", "왜", text)
    text = re.sub(r"ㅚ", "외", text)
    text = re.sub(r"ㅝ", "워", text)
    text = re.sub(r"ㅞ", "웨", text)
    text = re.sub(r"ㅟ", "위", text)
    text = re.sub(r"ㅢ", "의", text)
    return text

def normalize_multiline_text(long_text):
    texts = split_text(long_text)
    normalized_texts = [normalize_text(text).strip() for text in texts]
    return [text for text in normalized_texts if len(text) > 0]

def synthesize(text):
    global synthesizer
    wavs = synthesizer.tts(text, None, None)
    return wavs

if __name__ == "__main__":
    synthesizer = initialize_synthesizer()
    print(f"Symbols: {symbols}")
    texts = '''
    아래 문장들은 모델 학습을 위해 사용하지 않은 문장들입니다.
    서울특별시 특허허가과 허가과장 허과장.
    경찰청 철창살은 외철창살이고 검찰청 철창살은 쌍철창살이다.
    지향을 지양으로 오기하는 일을 지양하는 언어 습관을 지향해야 한다.
    그러니까 외계인이 우리 생각을 읽고 우리 생각을 우리가 다시 생각토록 해서 그 생각이 마치 우리가 생각한 것인 것처럼 속였다는 거냐?
    안 촉촉한 초코칩 나라에 살던 안 촉촉한 초코칩이 촉촉한 초코칩 나라의 촉촉한 초코칩을 보고 촉촉한 초코칩이 되고 싶어서 촉촉한 초코칩 나라에 갔는데 촉촉한 초코칩 나라의 촉촉한 문지기가 넌 촉촉한 초코칩이 아니고 안 촉촉한 초코칩이니까 안 촉촉한 초코칩 나라에서 살라고 해서 안 촉촉한 초코칩은 촉촉한 초코칩이 되는 것을 포기하고 안 촉촉한 눈물을 흘리며 안 촉촉한 초코칩 나라로 돌아갔다.
    '''
    for i, text in enumerate(normalize_multiline_text(texts)):
        print(f"Processing text {i}: {text}")
        wav = synthesize(text)
        import soundfile as sf
        sf.write(f"/content/output_{i}.wav", wav, synthesizer.tts_config.audio["sample_rate"])
"""

with open("synthesize_text.py", "w") as f:
    f.write(code)

# 스크립트 실행
!/content/tts_env/bin/python synthesize_text.py

# 생성된 오디오 파일 확인 및 재생
!ls /content/*.wav
from IPython.display import Audio, display
import glob
for wav_file in glob.glob("/content/*.wav"):
    print(f"Playing: {wav_file}")
    display(Audio(wav_file))

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/TTS

# 기존 WAV 파일 삭제
!rm -f /content/output_*.wav

# synthesize_text.py 파일 생성
code = """
import re
import sys
from unicodedata import normalize
from TTS.utils.synthesizer import Synthesizer
import g2pk

# symbols 정의
from TTS.tts.utils.text.symbols import symbols

# 한글 문자 추가
korean_chars = [chr(i) for i in range(0xAC00, 0xD7A4)]  # Hangul Syllables
extended_symbols = symbols + korean_chars

# Synthesizer 초기화
def initialize_synthesizer():
    synthesizer = Synthesizer(
        tts_checkpoint="/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/best_model.pth.tar",
        tts_config_path="/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/config.json",
        tts_speakers_file=None,
        vocoder_checkpoint="/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/best_model_293026.pth.tar",
        vocoder_config="/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/config.json",
        encoder_checkpoint=None,
        encoder_config=None,
        use_cuda=False,
    )
    return synthesizer

# g2pK 초기화
g2p = g2pk.G2p()

def normalize_text(text):
    print(f"Original text: {text}")
    text = text.strip()
    for c in ",;:":
        text = text.replace(c, ".")
    text = remove_duplicated_punctuations(text)
    print(f"After punctuation: {text}")
    text = jamo_text(text)
    print(f"After jamo: {text}")
    text = g2p.idioms(text)
    print(f"After idioms: {text}")
    text = g2pk.english.convert_eng(text, g2p.cmu)
    print(f"After english: {text}")
    text = g2pk.utils.annotate(text, g2p.mecab)
    print(f"After annotate: {text}")
    text = g2pk.numerals.convert_num(text)
    print(f"After numerals: {text}")
    text = re.sub("/[PJEB]", "", text)
    print(f"After regex: {text}")
    text = alphabet_text(text)
    print(f"After alphabet: {text}")
    text = normalize("NFD", text)
    text = "".join(c for c in text if c in extended_symbols or c in '.!?' or c.isspace())
    print(f"After symbols filter: {text}")
    text = normalize("NFC", text)
    text = text.strip()
    if len(text) == 0:
        print("Empty text, returning empty string")
        return ""
    if text in '.!?':
        print(f"Punctuation only, converting: {text}")
        return punctuation_text(text)
    if text[-1] not in '.!?':
        text += '.'
    print(f"Final normalized text: {text}")
    return text

def remove_duplicated_punctuations(text):
    text = re.sub(r"[.?!]+\?", "?", text)
    text = re.sub(r"[.?!]+!", "!", text)
    text = re.sub(r"[.?!]+\.", ".", text)
    return text

def split_text(text):
    text = remove_duplicated_punctuations(text)
    texts = []
    for subtext in re.findall(r'[^.!?\\n]*[.!?\\n]', text):
        texts.append(subtext.strip())
    return texts

def alphabet_text(text):
    text = re.sub(r"(a|A)", "에이", text)
    text = re.sub(r"(b|B)", "비", text)
    text = re.sub(r"(c|C)", "씨", text)
    text = re.sub(r"(d|D)", "디", text)
    text = re.sub(r"(e|E)", "이", text)
    text = re.sub(r"(f|F)", "에프", text)
    text = re.sub(r"(g|G)", "쥐", text)
    text = re.sub(r"(h|H)", "에이치", text)
    text = re.sub(r"(i|I)", "아이", text)
    text = re.sub(r"(j|J)", "제이", text)
    text = re.sub(r"(k|K)", "케이", text)
    text = re.sub(r"(l|L)", "엘", text)
    text = re.sub(r"(m|M)", "엠", text)
    text = re.sub(r"(n|N)", "엔", text)
    text = re.sub(r"(o|O)", "오", text)
    text = re.sub(r"(p|P)", "피", text)
    text = re.sub(r"(q|Q)", "큐", text)
    text = re.sub(r"(r|R)", "알", text)
    text = re.sub(r"(s|S)", "에스", text)
    text = re.sub(r"(t|T)", "티", text)
    text = re.sub(r"(u|U)", "유", text)
    text = re.sub(r"(v|V)", "브이", text)
    text = re.sub(r"(w|W)", "더블유", text)
    text = re.sub(r"(x|X)", "엑스", text)
    text = re.sub(r"(y|Y)", "와이", text)
    text = re.sub(r"(z|Z)", "지", text)
    return text

def punctuation_text(text):
    text = re.sub(r"!", "느낌표", text)
    text = re.sub(r"\?", "물음표", text)
    text = re.sub(r"\.", "마침표", text)
    return text

def jamo_text(text):
    text = re.sub(r"ㄱ", "기역", text)
    text = re.sub(r"ㄴ", "니은", text)
    text = re.sub(r"ㄷ", "디귿", text)
    text = re.sub(r"ㄹ", "리을", text)
    text = re.sub(r"ㅁ", "미음", text)
    text = re.sub(r"ㅂ", "비읍", text)
    text = re.sub(r"ㅅ", "시옷", text)
    text = re.sub(r"ㅇ", "이응", text)
    text = re.sub(r"ㅈ", "지읒", text)
    text = re.sub(r"ㅊ", "치읓", text)
    text = re.sub(r"ㅋ", "키읔", text)
    text = re.sub(r"ㅌ", "티읕", text)
    text = re.sub(r"ㅍ", "피읖", text)
    text = re.sub(r"ㅎ", "히읗", text)
    text = re.sub(r"ㄲ", "쌍기역", text)
    text = re.sub(r"ㄸ", "쌍디귿", text)
    text = re.sub(r"ㅃ", "쌍비읍", text)
    text = re.sub(r"ㅆ", "쌍시옷", text)
    text = re.sub(r"ㅉ", "쌍지읒", text)
    text = re.sub(r"ㄳ", "기역시옷", text)
    text = re.sub(r"ㄵ", "니은지읒", text)
    text = re.sub(r"ㄶ", "니은히읗", text)
    text = re.sub(r"ㄺ", "리을기역", text)
    text = re.sub(r"ㄻ", "리을미음", text)
    text = re.sub(r"ㄼ", "리을비읍", text)
    text = re.sub(r"ㄽ", "리을시옷", text)
    text = re.sub(r"ㄾ", "리을티읕", text)
    text = re.sub(r"ㄿ", "리을피읍", text)
    text = re.sub(r"ㅀ", "리을히읗", text)
    text = re.sub(r"ㅄ", "비읍시옷", text)
    text = re.sub(r"ㅏ", "아", text)
    text = re.sub(r"ㅑ", "야", text)
    text = re.sub(r"ㅓ", "어", text)
    text = re.sub(r"ㅕ", "여", text)
    text = re.sub(r"ㅗ", "오", text)
    text = re.sub(r"ㅛ", "요", text)
    text = re.sub(r"ㅜ", "우", text)
    text = re.sub(r"ㅠ", "유", text)
    text = re.sub(r"ㅡ", "으", text)
    text = re.sub(r"ㅣ", "이", text)
    text = re.sub(r"ㅐ", "애", text)
    text = re.sub(r"ㅒ", "얘", text)
    text = re.sub(r"ㅔ", "에", text)
    text = re.sub(r"ㅖ", "예", text)
    text = re.sub(r"ㅘ", "와", text)
    text = re.sub(r"ㅙ", "왜", text)
    text = re.sub(r"ㅚ", "외", text)
    text = re.sub(r"ㅝ", "워", text)
    text = re.sub(r"ㅞ", "웨", text)
    text = re.sub(r"ㅟ", "위", text)
    text = re.sub(r"ㅢ", "의", text)
    return text

def normalize_multiline_text(long_text):
    texts = split_text(long_text)
    normalized_texts = [normalize_text(text).strip() for text in texts]
    return [text for text in normalized_texts if len(text) > 0]

def synthesize(text):
    global synthesizer
    wavs = synthesizer.tts(text, None, None)
    return wavs

if __name__ == "__main__":
    synthesizer = initialize_synthesizer()
    print(f"Extended symbols count: {len(extended_symbols)}")
    texts = '''
    아래 문장들은 모델 학습을 위해 사용하지 않은 문장들입니다.
    서울특별시 특허허가과 허가과장 허과장.
    경찰청 철창살은 외철창살이고 검찰청 철창살은 쌍철창살이다.
    지향을 지양으로 오기하는 일을 지양하는 언어 습관을 지향해야 한다.
    그러니까 외계인이 우리 생각을 읽고 우리 생각을 우리가 다시 생각토록 해서 그 생각이 마치 우리가 생각한 것인 것처럼 속였다는 거냐?
    안 촉촉한 초코칩 나라에 살던 안 촉촉한 초코칩이 촉촉한 초코칩 나라의 촉촉한 초코칩을 보고 촉촉한 초코칩이 되고 싶어서 촉촉한 초코칩 나라에 갔는데 촉촉한 초코칩 나라의 촉촉한 문지기가 넌 촉촉한 초코칩이 아니고 안 촉촉한 초코칩이니까 안 촉촉한 초코칩 나라에서 살라고 해서 안 촉촉한 초코칩은 촉촉한 초코칩이 되는 것을 포기하고 안 촉촉한 눈물을 흘리며 안 촉촉한 초코칩 나라로 돌아갔다.
    '''
    for i, text in enumerate(normalize_multiline_text(texts)):
        print(f"Processing text {i}: {text}")
        wav = synthesize(text)
        import soundfile as sf
        sf.write(f"/content/output_{i}.wav", wav, synthesizer.tts_config.audio["sample_rate"])
"""

with open("synthesize_text.py", "w") as f:
    f.write(code)

# 스크립트 실행
!/content/tts_env/bin/python synthesize_text.py

# 생성된 오디오 파일 확인 및 재생
!ls /content/*.wav
from IPython.display import Audio, display
import glob
for wav_file in glob.glob("/content/*.wav"):
    print(f"Playing: {wav_file}")
    display(Audio(wav_file))

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/TTS

# Google Drive 마운트
from google.colab import drive
drive.mount('/content/drive')

# 기존 WAV 파일 삭제
!rm -f /content/output_*.wav

# 의존성 설치
!/content/tts_env/bin/pip install -q pysbd soundfile

# synthesize_text.py 파일 생성
code = """
import re
import sys
from unicodedata import normalize
from TTS.utils.synthesizer import Synthesizer
import g2pk

# symbols 정의
from TTS.tts.utils.text.symbols import symbols

# 한글 문자 추가
korean_chars = [chr(i) for i in range(0xAC00, 0xD7A4)]  # Hangul Syllables
extended_symbols = symbols + korean_chars

# Synthesizer 초기화
def initialize_synthesizer():
    synthesizer = Synthesizer(
        tts_checkpoint="/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/best_model.pth.tar",
        tts_config_path="/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/config.json",
        tts_speakers_file=None,
        vocoder_checkpoint="/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/best_model_293026.pth.tar",
        vocoder_config="/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/config.json",
        encoder_checkpoint=None,
        encoder_config=None,
        use_cuda=False,
    )
    return synthesizer

# g2pK 초기화
g2p = g2pk.G2p()

def normalize_text(text):
    print(f"Original text: {text}")
    text = text.strip()
    for c in ",;:":
        text = text.replace(c, ".")
    text = remove_duplicated_punctuations(text)
    print(f"After punctuation: {text}")
    text = jamo_text(text)
    print(f"After jamo: {text}")
    text = g2p.idioms(text)
    print(f"After idioms: {text}")
    text = g2pk.english.convert_eng(text, g2p.cmu)
    print(f"After english: {text}")
    text = g2pk.utils.annotate(text, g2p.mecab)
    print(f"After annotate: {text}")
    text = g2pk.numerals.convert_num(text)
    print(f"After numerals: {text}")
    text = re.sub("/[PJEB]", "", text)
    print(f"After regex: {text}")
    text = alphabet_text(text)
    print(f"After alphabet: {text}")
    # NFD 정규화 생략하여 한글 분해 방지
    # text = normalize("NFD", text)
    # symbols 필터링 완화: 한글, 공백, 문장부호 유지
    text = "".join(c for c in text if (0xAC00 <= ord(c) <= 0xD7A3 or c.isspace() or c in '.!?' or c in symbols))
    print(f"After symbols filter: {text}")
    text = normalize("NFC", text)
    text = text.strip()
    if len(text) == 0:
        print("Empty text, returning empty string")
        return ""
    if text in '.!?':
        print(f"Punctuation only, converting: {text}")
        return punctuation_text(text)
    if text[-1] not in '.!?':
        text += '.'
    print(f"Final normalized text: {text}")
    return text

def remove_duplicated_punctuations(text):
    text = re.sub(r"[.?!]+\?", "?", text)
    text = re.sub(r"[.?!]+!", "!", text)
    text = re.sub(r"[.?!]+\.", ".", text)
    return text

def split_text(text):
    text = remove_duplicated_punctuations(text)
    texts = []
    for subtext in re.findall(r'[^.!?\\n]*[.!?\\n]', text):
        texts.append(subtext.strip())
    return texts

def alphabet_text(text):
    text = re.sub(r"(a|A)", "에이", text)
    text = re.sub(r"(b|B)", "비", text)
    text = re.sub(r"(c|C)", "씨", text)
    text = re.sub(r"(d|D)", "디", text)
    text = re.sub(r"(e|E)", "이", text)
    text = re.sub(r"(f|F)", "에프", text)
    text = re.sub(r"(g|G)", "쥐", text)
    text = re.sub(r"(h|H)", "에이치", text)
    text = re.sub(r"(i|I)", "아이", text)
    text = re.sub(r"(j|J)", "제이", text)
    text = re.sub(r"(k|K)", "케이", text)
    text = re.sub(r"(l|L)", "엘", text)
    text = re.sub(r"(m|M)", "엠", text)
    text = re.sub(r"(n|N)", "엔", text)
    text = re.sub(r"(o|O)", "오", text)
    text = re.sub(r"(p|P)", "피", text)
    text = re.sub(r"(q|Q)", "큐", text)
    text = re.sub(r"(r|R)", "알", text)
    text = re.sub(r"(s|S)", "에스", text)
    text = re.sub(r"(t|T)", "티", text)
    text = re.sub(r"(u|U)", "유", text)
    text = re.sub(r"(v|V)", "브이", text)
    text = re.sub(r"(w|W)", "더블유", text)
    text = re.sub(r"(x|X)", "엑스", text)
    text = re.sub(r"(y|Y)", "와이", text)
    text = re.sub(r"(z|Z)", "지", text)
    return text

def punctuation_text(text):
    text = re.sub(r"!", "느낌표", text)
    text = re.sub(r"\?", "물음표", text)
    text = re.sub(r"\.", "마침표", text)
    return text

def jamo_text(text):
    text = re.sub(r"ㄱ", "기역", text)
    text = re.sub(r"ㄴ", "니은", text)
    text = re.sub(r"ㄷ", "디귿", text)
    text = re.sub(r"ㄹ", "리을", text)
    text = re.sub(r"ㅁ", "미음", text)
    text = re.sub(r"ㅂ", "비읍", text)
    text = re.sub(r"ㅅ", "시옷", text)
    text = re.sub(r"ㅇ", "이응", text)
    text = re.sub(r"ㅈ", "지읒", text)
    text = re.sub(r"ㅊ", "치읓", text)
    text = re.sub(r"ㅋ", "키읔", text)
    text = re.sub(r"ㅌ", "티읕", text)
    text = re.sub(r"ㅍ", "피읖", text)
    text = re.sub(r"ㅎ", "히읗", text)
    text = re.sub(r"ㄲ", "쌍기역", text)
    text = re.sub(r"ㄸ", "쌍디귿", text)
    text = re.sub(r"ㅃ", "쌍비읍", text)
    text = re.sub(r"ㅆ", "쌍시옷", text)
    text = re.sub(r"ㅉ", "쌍지읒", text)
    text = re.sub(r"ㄳ", "기역시옷", text)
    text = re.sub(r"ㄵ", "니은지읒", text)
    text = re.sub(r"ㄶ", "니은히읗", text)
    text = re.sub(r"ㄺ", "리을기역", text)
    text = re.sub(r"ㄻ", "리을미음", text)
    text = re.sub(r"ㄼ", "리을비읍", text)
    text = re.sub(r"ㄽ", "리을시옷", text)
    text = re.sub(r"ㄾ", "리을티읕", text)
    text = re.sub(r"ㄿ", "리을피읍", text)
    text = re.sub(r"ㅀ", "리을히읗", text)
    text = re.sub(r"ㅄ", "비읍시옷", text)
    text = re.sub(r"ㅏ", "아", text)
    text = re.sub(r"ㅑ", "야", text)
    text = re.sub(r"ㅓ", "어", text)
    text = re.sub(r"ㅕ", "여", text)
    text = re.sub(r"ㅗ", "오", text)
    text = re.sub(r"ㅛ", "요", text)
    text = re.sub(r"ㅜ", "우", text)
    text = re.sub(r"ㅠ", "유", text)
    text = re.sub(r"ㅡ", "으", text)
    text = re.sub(r"ㅣ", "이", text)
    text = re.sub(r"ㅐ", "애", text)
    text = re.sub(r"ㅒ", "얘", text)
    text = re.sub(r"ㅔ", "에", text)
    text = re.sub(r"ㅖ", "예", text)
    text = re.sub(r"ㅘ", "와", text)
    text = re.sub(r"ㅙ", "왜", text)
    text = re.sub(r"ㅚ", "외", text)
    text = re.sub(r"ㅝ", "워", text)
    text = re.sub(r"ㅞ", "웨", text)
    text = re.sub(r"ㅟ", "위", text)
    text = re.sub(r"ㅢ", "의", text)
    return text

def normalize_multiline_text(long_text):
    texts = split_text(long_text)
    normalized_texts = [normalize_text(text).strip() for text in texts]
    return [text for text in normalized_texts if len(text) > 0]

def synthesize(text):
    global synthesizer
    print(f"Synthesizing text: {text}")
    wavs = synthesizer.tts(text, None, None)
    return wavs

if __name__ == "__main__":
    synthesizer = initialize_synthesizer()
    print(f"Extended symbols count: {len(extended_symbols)}")
    print(f"Sample korean chars: {korean_chars[:10]}")
    texts = '''
    아래 문장들은 모델 학습을 위해 사용하지 않은 문장들입니다.
    서울특별시 특허허가과 허가과장 허과장.
    경찰청 철창살은 외철창살이고 검찰청 철창살은 쌍철창살이다.
    지향을 지양으로 오기하는 일을 지양하는 언어 습관을 지향해야 한다.
    그러니까 외계인이 우리 생각을 읽고 우리 생각을 우리가 다시 생각토록 해서 그 생각이 마치 우리가 생각한 것인 것처럼 속였다는 거냐?
    안 촉촉한 초코칩 나라에 살던 안 촉촉한 초코칩이 촉촉한 초코칩 나라의 촉촉한 초코칩을 보고 촉촉한 초코칩이 되고 싶어서 촉촉한 초코칩 나라에 갔는데 촉촉한 초코칩 나라의 촉촉한 문지기가 넌 촉촉한 초코칩이 아니고 안 촉촉한 초코칩이니까 안 촉촉한 초코칩 나라에서 살라고 해서 안 촉촉한 초코칩은 촉촉한 초코칩이 되는 것을 포기하고 안 촉촉한 눈물을 흘리며 안 촉촉한 초코칩 나라로 돌아갔다.
    '''
    for i, text in enumerate(normalize_multiline_text(texts)):
        print(f"Processing text {i}: {text}")
        wav = synthesize(text)
        import soundfile as sf
        sf.write(f"/content/output_{i}.wav", wav, synthesizer.tts_config.audio["sample_rate"])
"""

with open("synthesize_text.py", "w") as f:
    f.write(code)

# Python 버전 및 모듈 확인
!/content/tts_env/bin/python --version
!/content/tts_env/bin/python -c "import TTS; print(TTS.__version__)"
!/content/tts_env/bin/python -c "import pysbd; print(pysbd.__version__)"
!/content/tts_env/bin/python -c "import g2pk; print('g2pk installed')"

# TTS 재설치
!/content/tts_env/bin/pip install -q --no-cache-dir -e .

# 모델 및 설정 파일 확인
!ls "/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/best_model.pth.tar"
!ls "/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/config.json"
!ls "/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/best_model_293026.pth.tar"
!ls "/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/config.json"

# 샘플레이트 확인
!cat "/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/config.json" | grep sample_rate
!cat "/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/config.json" | grep sample_rate

# 스크립트 실행
!/content/tts_env/bin/python synthesize_text.py

# 생성된 오디오 파일 확인 및 재생
!ls /content/*.wav
from IPython.display import Audio, display
import glob
for wav_file in glob.glob("/content/*.wav"):
    print(f"Playing: {wav_file}")
    display(Audio(wav_file))

texts = """
아래 문장들은 모델 학습을 위해 사용하지 않은 문장들입니다.
서울특별시 특허허가과 허가과장 허과장.
경찰청 철창살은 외철창살이고 검찰청 철창살은 쌍철창살이다.
지향을 지양으로 오기하는 일을 지양하는 언어 습관을 지향해야 한다.
그러니까 외계인이 우리 생각을 읽고 우리 생각을 우리가 다시 생각토록 해서 그 생각이 마치 우리가 생각한 것인 것처럼 속였다는 거냐?
안 촉촉한 초코칩 나라에 살던 안 촉촉한 초코칩이 촉촉한 초코칩 나라의 촉촉한 초코칩을 보고 촉촉한 초코칩이 되고 싶어서 촉촉한 초코칩 나라에 갔는데 촉촉한 초코칩 나라의 촉촉한 문지기가 넌 촉촉한 초코칩이 아니고 안 촉촉한 초코칩이니까 안 촉촉한 초코칩 나라에서 살라고 해서 안 촉촉한 초코칩은 촉촉한 초코칩이 되는 것을 포기하고 안 촉촉한 눈물을 흘리며 안 촉촉한 초코칩 나라로 돌아갔다.
"""
for text in normalize_multiline_text(texts):
    wav = synthesizer.tts(text, None, None)
    IPython.display.display(IPython.display.Audio(wav, rate=22050))

"""# **6.테스트**"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/TTS

# Google Drive 마운트
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# 기존 WAV 파일 삭제
!rm -f /content/output_*.wav /content/input_*.wav

# 시스템 의존성 설치
!apt-get update -qq && apt-get install -y -qq libportaudio2

# 가상 환경 확인 및 필수 모듈 설치
!/content/tts_env/bin/pip install --upgrade pip
!/content/tts_env/bin/pip install -q --no-cache-dir speechrecognition transformers sounddevice soundfile git+https://github.com/openai/whisper.git

# synthesize_text.py 파일 생성
code = """
import re
import sys
import numpy as np
from unicodedata import normalize
from TTS.utils.synthesizer import Synthesizer
import g2pk
import speech_recognition as sr
from transformers import pipeline
import soundfile as sf
import whisper
import warnings
warnings.filterwarnings("ignore", category=FutureWarning)

# symbols 정의
from TTS.tts.utils.text.symbols import symbols

# 한글 문자 추가
korean_chars = [chr(i) for i in range(0xAC00, 0xD7A4)]  # Hangul Syllables
extended_symbols = symbols + korean_chars

# Synthesizer 초기화
def initialize_synthesizer():
    synthesizer = Synthesizer(
        tts_checkpoint="/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/best_model.pth.tar",
        tts_config_path="/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/config.json",
        tts_speakers_file=None,
        vocoder_checkpoint="/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/best_model_293026.pth.tar",
        vocoder_config="/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/config.json",
        encoder_checkpoint=None,
        encoder_config=None,
        use_cuda=False,
    )
    return synthesizer

# g2pK 초기화
g2p = g2pk.G2p()

# 번역 파이프라인 초기화
translator = pipeline("translation", model="Helsinki-NLP/opus-mt-ko-en")

# Whisper 모델 초기화
whisper_model = whisper.load_model("tiny")

def normalize_text(text, is_korean=True):
    print(f"Original text: {text}")
    text = text.strip()
    if is_korean:
        for c in ",;:":
            text = text.replace(c, ".")
        text = remove_duplicated_punctuations(text)
        print(f"After punctuation: {text}")
        text = jamo_text(text)
        print(f"After jamo: {text}")
        text = g2p.idioms(text)
        print(f"After idioms: {text}")
        text = g2pk.english.convert_eng(text, g2p.cmu)
        print(f"After english: {text}")
        text = g2pk.utils.annotate(text, g2p.mecab)
        print(f"After annotate: {text}")
        text = g2pk.numerals.convert_num(text)
        print(f"After numerals: {text}")
        text = re.sub("/[PJEB]", "", text)
        print(f"After regex: {text}")
        text = alphabet_text(text)
        print(f"After alphabet: {text}")
        text = "".join(c for c in text if (0xAC00 <= ord(c) <= 0xD7A3 or c.isspace() or c in '.!?' or c in symbols))
        print(f"After symbols filter: {text}")
        text = normalize("NFC", text)
    else:
        text = "".join(c for c in text if c.isalnum() or c.isspace() or c in '.!?')
        print(f"After symbols filter (English): {text}")
    text = text.strip()
    if len(text) == 0:
        print("Empty text, returning empty string")
        return ""
    if text in '.!?':
        print(f"Punctuation only, converting: {text}")
        return punctuation_text(text)
    if text[-1] not in '.!?':
        text += '.'
    print(f"Final normalized text: {text}")
    return text

def remove_duplicated_punctuations(text):
    text = re.sub(r"[.?!]+\?", "?", text)
    text = re.sub(r"[.?!]+!", "!", text)
    text = re.sub(r"[.?!]+\.", ".", text)
    return text

def alphabet_text(text):
    text = re.sub(r"(a|A)", "에이", text)
    text = re.sub(r"(b|B)", "비", text)
    text = re.sub(r"(c|C)", "씨", text)
    text = re.sub(r"(d|D)", "디", text)
    text = re.sub(r"(e|E)", "이", text)
    text = re.sub(r"(f|F)", "에프", text)
    text = re.sub(r"(g|G)", "쥐", text)
    text = re.sub(r"(h|H)", "에이치", text)
    text = re.sub(r"(i|I)", "아이", text)
    text = re.sub(r"(j|J)", "제이", text)
    text = re.sub(r"(k|K)", "케이", text)
    text = re.sub(r"(l|L)", "엘", text)
    text = re.sub(r"(m|M)", "엠", text)
    text = re.sub(r"(n|N)", "엔", text)
    text = re.sub(r"(o|O)", "오", text)
    text = re.sub(r"(p|P)", "피", text)
    text = re.sub(r"(q|Q)", "큐", text)
    text = re.sub(r"(r|R)", "알", text)
    text = re.sub(r"(s|S)", "에스", text)
    text = re.sub(r"(t|T)", "티", text)
    text = re.sub(r"(u|U)", "유", text)
    text = re.sub(r"(v|V)", "브이", text)
    text = re.sub(r"(w|W)", "더블유", text)
    text = re.sub(r"(x|X)", "엑스", text)
    text = re.sub(r"(y|Y)", "와이", text)
    text = re.sub(r"(z|Z)", "지", text)
    return text

def punctuation_text(text):
    text = re.sub(r"!", "느낌표", text)
    text = re.sub(r"\?", "물음표", text)
    text = re.sub(r"\.", "마침표", text)
    return text

def jamo_text(text):
    text = re.sub(r"ㄱ", "기역", text)
    text = re.sub(r"ㄴ", "니은", text)
    text = re.sub(r"ㄷ", "디귿", text)
    text = re.sub(r"ㄹ", "리을", text)
    text = re.sub(r"ㅁ", "미음", text)
    text = re.sub(r"ㅂ", "비읍", text)
    text = re.sub(r"ㅅ", "시옷", text)
    text = re.sub(r"ㅇ", "이응", text)
    text = re.sub(r"ㅈ", "지읒", text)
    text = re.sub(r"ㅊ", "치읓", text)
    text = re.sub(r"ㅋ", "키읔", text)
    text = re.sub(r"ㅌ", "티읕", text)
    text = re.sub(r"ㅍ", "피읖", text)
    text = re.sub(r"ㅎ", "히읗", text)
    text = re.sub(r"ㄲ", "쌍기역", text)
    text = re.sub(r"ㄸ", "쌍디귿", text)
    text = re.sub(r"ㅃ", "쌍비읍", text)
    text = re.sub(r"ㅆ", "쌍시옷", text)
    text = re.sub(r"ㅉ", "쌍지읒", text)
    text = re.sub(r"ㄳ", "기역시옷", text)
    text = re.sub(r"ㄵ", "니은지읒", text)
    text = re.sub(r"ㄶ", "니은히읗", text)
    text = re.sub(r"ㄺ", "리을기역", text)
    text = re.sub(r"ㄻ", "리을미음", text)
    text = re.sub(r"ㄼ", "리을비읍", text)
    text = re.sub(r"ㄽ", "리을시옷", text)
    text = re.sub(r"ㄾ", "리을티읕", text)
    text = re.sub(r"ㄿ", "리을피읍", text)
    text = re.sub(r"ㅀ", "리을히읗", text)
    text = re.sub(r"ㅄ", "비읍시옷", text)
    text = re.sub(r"ㅏ", "아", text)
    text = re.sub(r"ㅑ", "야", text)
    text = re.sub(r"ㅓ", "어", text)
    text = re.sub(r"ㅕ", "여", text)
    text = re.sub(r"ㅗ", "오", text)
    text = re.sub(r"ㅛ", "요", text)
    text = re.sub(r"ㅜ", "우", text)
    text = re.sub(r"ㅠ", "유", text)
    text = re.sub(r"ㅡ", "으", text)
    text = re.sub(r"ㅣ", "이", text)
    text = re.sub(r"ㅐ", "애", text)
    text = re.sub(r"ㅒ", "얘", text)
    text = re.sub(r"ㅔ", "에", text)
    text = re.sub(r"ㅖ", "예", text)
    text = re.sub(r"ㅘ", "와", text)
    text = re.sub(r"ㅙ", "왜", text)
    text = re.sub(r"ㅚ", "외", text)
    text = re.sub(r"ㅝ", "워", text)
    text = re.sub(r"ㅞ", "웨", text)
    text = re.sub(r"ㅟ", "위", text)
    text = re.sub(r"ㅢ", "의", text)
    return text

def speech_to_text(audio_file):
    print(f"Transcribing {audio_file} with Whisper...")
    result = whisper_model.transcribe(audio_file, language="ko")
    text = result['text'].strip()
    print(f"Recognized text: {text}")
    return text if text else ""

def translate_text(text):
    if not text:
        return ""
    result = translator(text)[0]['translation_text']
    print(f"Translated text: {result}")
    return result

def synthesize(text):
    global synthesizer
    print(f"Synthesizing text: {text}")
    wavs = synthesizer.tts(text, None, None)
    return wavs

if __name__ == "__main__":
    synthesizer = initialize_synthesizer()
    print(f"Extended symbols count: {len(extended_symbols)}")
    print(f"Sample korean chars: {korean_chars[:10]}")

    # WAV 파일 업로드
    input_audio = "/content/input_audio.wav"
    print("Please upload your Korean audio file as /content/input_audio.wav")
    from google.colab import files
    uploaded = files.upload()
    if not uploaded:
        print("No file uploaded, exiting")
        sys.exit(1)

    # 오디오 파일 포맷 변환 (16kHz, 모노)
    import os
    if os.path.exists(input_audio):
        converted_audio = "/content/input_audio_converted.wav"
        !ffmpeg -y -i {input_audio} -ar 16000 -ac 1 {converted_audio}
        input_audio = converted_audio
        print(f"Converted audio to {input_audio}")

    # STT: 한국어 음성을 텍스트로 변환
    korean_text = speech_to_text(input_audio)
    if not korean_text:
        print("No text recognized, exiting")
        sys.exit(1)
    korean_text = normalize_text(korean_text, is_korean=True)

    # 번역: 한국어 → 영어
    english_text = translate_text(korean_text)
    if not english_text:
        print("No translation, exiting")
        sys.exit(1)
    english_text = normalize_text(english_text, is_korean=False)

    # TTS: 영어 텍스트를 음성으로 합성
    wav = synthesize(english_text)
    output_file = "/content/output_english.wav"
    sf.write(output_file, wav, synthesizer.tts_config.audio["sample_rate"])
    print(f"English audio saved as {output_file}")
"""

with open("synthesize_text.py", "w") as f:
    f.write(code)

# Python 버전 및 모듈 확인
!/content/tts_env/bin/python --version
!/content/tts_env/bin/python -c "import TTS; print(TTS.__version__)"
!/content/tts_env/bin/python -c "import speech_recognition; print('speech_recognition installed')"
!/content/tts_env/bin/python -c "import transformers; print(transformers.__version__)"
!/content/tts_env/bin/python -c "import sounddevice; print('sounddevice installed')"
!/content/tts_env/bin/python -c "import soundfile; print('soundfile installed')"
!/content/tts_env/bin/python -c "import whisper; print('whisper installed')"

# TTS 재설치
!/content/tts_env/bin/pip install -q --no-cache-dir -e .

# 모델 및 설정 파일 확인
!ls "/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/best_model.pth.tar"
!ls "/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/config.json"
!ls "/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/best_model_293026.pth.tar"
!ls "/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/config.json"

# 샘플레이트 확인
!cat "/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/config.json" | grep sample_rate
!cat "/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/config.json" | grep sample_rate

# ffmpeg 설치 확인
!ffmpeg -version

# 스크립트 실행
!/content/tts_env/bin/python synthesize_text.py

# 생성된 오디오 파일 확인 및 재생
!ls /content/*.wav
from IPython.display import Audio, display
import glob
for wav_file in glob.glob("/content/*.wav"):
    print(f"Playing: {wav_file}")
    display(Audio(wav_file))

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/TTS

# Google Drive 마운트 (필요 시)
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# synthesize_text.py 수정
code = """
import re
import sys
import numpy as np
from unicodedata import normalize
from TTS.utils.synthesizer import Synthesizer
import g2pk
from transformers import pipeline
import soundfile as sf
import whisper
import subprocess
import warnings
warnings.filterwarnings("ignore", category=FutureWarning)

# symbols 정의
from TTS.tts.utils.text.symbols import symbols

# 한글 문자 추가
korean_chars = [chr(i) for i in range(0xAC00, 0xD7A4)]  # Hangul Syllables
extended_symbols = symbols + korean_chars

# Synthesizer 초기화
def initialize_synthesizer():
    synthesizer = Synthesizer(
        tts_checkpoint="/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/best_model.pth.tar",
        tts_config_path="/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/config.json",
        tts_speakers_file=None,
        vocoder_checkpoint="/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/best_model_293026.pth.tar",
        vocoder_config="/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/config.json",
        encoder_checkpoint=None,
        encoder_config=None,
        use_cuda=False,
    )
    return synthesizer

# g2pK 초기화
g2p = g2pk.G2p()

# 번역 파이프라인 초기화
translator = pipeline("translation", model="Helsinki-NLP/opus-mt-ko-en")

# Whisper 모델 초기화
whisper_model = whisper.load_model("tiny")

def normalize_text(text, is_korean=True):
    print(f"Original text: {text}")
    text = text.strip()
    if is_korean:
        for c in ",;:":
            text = text.replace(c, ".")
        text = remove_duplicated_punctuations(text)
        print(f"After punctuation: {text}")
        text = jamo_text(text)
        print(f"After jamo: {text}")
        text = g2p.idioms(text)
        print(f"After idioms: {text}")
        text = g2pk.english.convert_eng(text, g2p.cmu)
        print(f"After english: {text}")
        text = g2pk.utils.annotate(text, g2p.mecab)
        print(f"After annotate: {text}")
        text = g2pk.numerals.convert_num(text)
        print(f"After numerals: {text}")
        text = re.sub("/[PJEB]", "", text)
        print(f"After regex: {text}")
        text = alphabet_text(text)
        print(f"After alphabet: {text}")
        text = "".join(c for c in text if (0xAC00 <= ord(c) <= 0xD7A3 or c.isspace() or c in '.!?' or c in symbols))
        print(f"After symbols filter: {text}")
        text = normalize("NFC", text)
    else:
        text = "".join(c for c in text if c.isalnum() or c.isspace() or c in '.!?')
        print(f"After symbols filter (English): {text}")
    text = text.strip()
    if len(text) == 0:
        print("Empty text, returning empty string")
        return ""
    if text in '.!?':
        print(f"Punctuation only, converting: {text}")
        return punctuation_text(text)
    if text[-1] not in '.!?':
        text += '.'
    print(f"Final normalized text: {text}")
    return text

def remove_duplicated_punctuations(text):
    text = re.sub(r"[.?!]+\?", "?", text)
    text = re.sub(r"[.?!]+!", "!", text)
    text = re.sub(r"[.?!]+\.", ".", text)
    return text

def alphabet_text(text):
    text = re.sub(r"(a|A)", "에이", text)
    text = re.sub(r"(b|B)", "비", text)
    text = re.sub(r"(c|C)", "씨", text)
    text = re.sub(r"(d|D)", "디", text)
    text = re.sub(r"(e|E)", "이", text)
    text = re.sub(r"(f|F)", "에프", text)
    text = re.sub(r"(g|G)", "쥐", text)
    text = re.sub(r"(h|H)", "에이치", text)
    text = re.sub(r"(i|I)", "아이", text)
    text = re.sub(r"(j|J)", "제이", text)
    text = re.sub(r"(k|K)", "케이", text)
    text = re.sub(r"(l|L)", "엘", text)
    text = re.sub(r"(m|M)", "엠", text)
    text = re.sub(r"(n|N)", "엔", text)
    text = re.sub(r"(o|O)", "오", text)
    text = re.sub(r"(p|P)", "피", text)
    text = re.sub(r"(q|Q)", "큐", text)
    text = re.sub(r"(r|R)", "알", text)
    text = re.sub(r"(s|S)", "에스", text)
    text = re.sub(r"(t|T)", "티", text)
    text = re.sub(r"(u|U)", "유", text)
    text = re.sub(r"(v|V)", "브이", text)
    text = re.sub(r"(w|W)", "더블유", text)
    text = re.sub(r"(x|X)", "엑스", text)
    text = re.sub(r"(y|Y)", "와이", text)
    text = re.sub(r"(z|Z)", "지", text)
    return text

def punctuation_text(text):
    text = re.sub(r"!", "느낌표", text)
    text = re.sub(r"\?", "물음표", text)
    text = re.sub(r"\.", "마침표", text)
    return text

def jamo_text(text):
    text = re.sub(r"ㄱ", "기역", text)
    text = re.sub(r"ㄴ", "니은", text)
    text = re.sub(r"ㄷ", "디귿", text)
    text = re.sub(r"ㄹ", "리을", text)
    text = re.sub(r"ㅁ", "미음", text)
    text = re.sub(r"ㅂ", "비읍", text)
    text = re.sub(r"ㅅ", "시옷", text)
    text = re.sub(r"ㅇ", "이응", text)
    text = re.sub(r"ㅈ", "지읒", text)
    text = re.sub(r"ㅊ", "치읓", text)
    text = re.sub(r"ㅋ", "키읔", text)
    text = re.sub(r"ㅌ", "티읕", text)
    text = re.sub(r"ㅍ", "피읖", text)
    text = re.sub(r"ㅎ", "히읗", text)
    text = re.sub(r"ㄲ", "쌍기역", text)
    text = re.sub(r"ㄸ", "쌍디귿", text)
    text = re.sub(r"ㅃ", "쌍비읍", text)
    text = re.sub(r"ㅆ", "쌍시옷", text)
    text = re.sub(r"ㅉ", "쌍지읒", text)
    text = re.sub(r"ㄳ", "기역시옷", text)
    text = re.sub(r"ㄵ", "니은지읒", text)
    text = re.sub(r"ㄶ", "니은히읗", text)
    text = re.sub(r"ㄺ", "리을기역", text)
    text = re.sub(r"ㄻ", "리을미음", text)
    text = re.sub(r"ㄼ", "리을비읍", text)
    text = re.sub(r"ㄽ", "리을시옷", text)
    text = re.sub(r"ㄾ", "리을티읕", text)
    text = re.sub(r"ㄿ", "리을피읍", text)
    text = re.sub(r"ㅀ", "리을히읗", text)
    text = re.sub(r"ㅄ", "비읍시옷", text)
    text = re.sub(r"ㅏ", "아", text)
    text = re.sub(r"ㅑ", "야", text)
    text = re.sub(r"ㅓ", "어", text)
    text = re.sub(r"ㅕ", "여", text)
    text = re.sub(r"ㅗ", "오", text)
    text = re.sub(r"ㅛ", "요", text)
    text = re.sub(r"ㅜ", "우", text)
    text = re.sub(r"ㅠ", "유", text)
    text = re.sub(r"ㅡ", "으", text)
    text = re.sub(r"ㅣ", "이", text)
    text = re.sub(r"ㅐ", "애", text)
    text = re.sub(r"ㅒ", "얘", text)
    text = re.sub(r"ㅔ", "에", text)
    text = re.sub(r"ㅖ", "예", text)
    text = re.sub(r"ㅘ", "와", text)
    text = re.sub(r"ㅙ", "왜", text)
    text = re.sub(r"ㅚ", "외", text)
    text = re.sub(r"ㅝ", "워", text)
    text = re.sub(r"ㅞ", "웨", text)
    text = re.sub(r"ㅟ", "위", text)
    text = re.sub(r"ㅢ", "의", text)
    return text

def convert_audio(input_path, output_path, sample_rate=16000):
    print(f"Converting {input_path} to {output_path} (16kHz, mono)...")
    cmd = ["ffmpeg", "-y", "-i", input_path, "-ar", str(sample_rate), "-ac", "1", output_path]
    try:
        subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        print(f"Conversion complete: {output_path}")
    except subprocess.CalledProcessError as e:
        print(f"FFmpeg error: {e.stderr.decode()}")
        sys.exit(1)

def speech_to_text(audio_file):
    print(f"Transcribing {audio_file} with Whisper...")
    result = whisper_model.transcribe(audio_file, language="ko")
    text = result['text'].strip()
    print(f"Recognized text: {text}")
    return text if text else ""

def translate_text(text):
    if not text:
        return ""
    result = translator(text)[0]['translation_text']
    print(f"Translated text: {result}")
    return result

def synthesize(text):
    global synthesizer
    print(f"Synthesizing text: {text}")
    wavs = synthesizer.tts(text, None, None)
    return wavs

if __name__ == "__main__":
    synthesizer = initialize_synthesizer()
    print(f"Extended symbols count: {len(extended_symbols)}")
    print(f"Sample korean chars: {korean_chars[:10]}")

    # WAV 파일 업로드
    input_audio = "/content/input_audio.wav"
    print("Please upload your Korean audio file as /content/input_audio.wav")
    from google.colab import files
    import os
    uploaded = files.upload()
    if not uploaded:
        print("No file uploaded, exiting")
        sys.exit(1)

    # 오디오 파일 포맷 변환 (16kHz, 모노)
    if os.path.exists(input_audio):
        converted_audio = "/content/input_audio_converted.wav"
        convert_audio(input_audio, converted_audio)
        input_audio = converted_audio

    # STT: 한국어 음성을 텍스트로 변환
    korean_text = speech_to_text(input_audio)
    if not korean_text:
        print("No text recognized, exiting")
        sys.exit(1)
    korean_text = normalize_text(korean_text, is_korean=True)

    # 번역: 한국어 → 영어
    english_text = translate_text(korean_text)
    if not english_text:
        print("No translation, exiting")
        sys.exit(1)
    english_text = normalize_text(english_text, is_korean=False)

    # TTS: 영어 텍스트를 음성으로 합성
    wav = synthesize(english_text)
    output_file = "/content/output_english.wav"
    sf.write(output_file, wav, synthesizer.tts_config.audio["sample_rate"])
    print(f"English audio saved as {output_file}")
"""

with open("synthesize_text.py", "w") as f:
    f.write(code)

# 스크립트 실행
!/content/tts_env/bin/python synthesize_text.py

# 생성된 오디오 파일 확인 및 재생
!ls /content/*.wav
from IPython.display import Audio, display
import glob
for wav_file in glob.glob("/content/*.wav"):
    print(f"Playing: {wav_file}")
    display(Audio(wav_file))

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/TTS

# sentencepiece 설치
!/content/tts_env/bin/pip install sentencepiece

# 모듈 설치 확인
!/content/tts_env/bin/pip list | grep -E "sentencepiece|transformers|soundfile|whisper|g2pK"

# Google Drive 마운트 (필요 시)
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# 입력 WAV 파일 확인
!ls /content/*.wav

# 스크립트 실행
!/content/tts_env/bin/python synthesize_text.py

# 생성된 오디오 파일 확인 및 재생
!ls /content/*.wav
from IPython.display import Audio, display
import glob
for wav_file in glob.glob("/content/*.wav"):
    print(f"Playing: {wav_file}")
    display(Audio(wav_file))

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/TTS

# 필수 모듈 설치
!/content/tts_env/bin/pip install -q sentencepiece transformers==4.46.3 soundfile==0.12.1 git+https://github.com/openai/whisper.git g2pK

# 모듈 설치 확인
!/content/tts_env/bin/pip list | grep -E "sentencepiece|transformers|soundfile|whisper|g2pK"

# Google Drive 마운트
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# 입력 WAV 파일 확인
!ls /content/*.wav

# synthesize_text.py 수정
code = """
import re
import sys
import numpy as np
from unicodedata import normalize
from TTS.utils.synthesizer import Synthesizer
import g2pk
from transformers import pipeline
import soundfile as sf
import whisper
import subprocess
import warnings
warnings.filterwarnings("ignore", category=FutureWarning)

# symbols 정의
from TTS.tts.utils.text.symbols import symbols

# 한글 문자 추가
korean_chars = [chr(i) for i in range(0xAC00, 0xD7A4)]  # Hangul Syllables
extended_symbols = symbols + korean_chars

# Synthesizer 초기화
def initialize_synthesizer():
    synthesizer = Synthesizer(
        tts_checkpoint="/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/best_model.pth.tar",
        tts_config_path="/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/config.json",
        tts_speakers_file=None,
        vocoder_checkpoint="/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/best_model_293026.pth.tar",
        vocoder_config="/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/config.json",
        encoder_checkpoint=None,
        encoder_config=None,
        use_cuda=False,
    )
    return synthesizer

# g2pK 초기화
g2p = g2pk.G2p()

# 번역 파이프라인 초기화
translator = pipeline("translation", model="Helsinki-NLP/opus-mt-ko-en")

# Whisper 모델 초기화
whisper_model = whisper.load_model("tiny")

def normalize_text(text, is_korean=True):
    print(f"Original text: {text}")
    text = text.strip()
    if is_korean:
        for c in ",;:":
            text = text.replace(c, ".")
        text = remove_duplicated_punctuations(text)
        print(f"After punctuation: {text}")
        text = jamo_text(text)
        print(f"After jamo: {text}")
        text = g2p.idioms(text)
        print(f"After idioms: {text}")
        text = g2pk.english.convert_eng(text, g2p.cmu)
        print(f"After english: {text}")
        text = g2pk.utils.annotate(text, g2p.mecab)
        print(f"After annotate: {text}")
        text = g2pk.numerals.convert_num(text)
        print(f"After numerals: {text}")
        text = re.sub("/[PJEB]", "", text)
        print(f"After regex: {text}")
        text = alphabet_text(text)
        print(f"After alphabet: {text}")
        text = "".join(c for c in text if (0xAC00 <= ord(c) <= 0xD7A3 or c.isspace() or c in '.!?' or c in symbols))
        print(f"After symbols filter: {text}")
        text = normalize("NFC", text)
    else:
        text = "".join(c for c in text if c.isalnum() or c.isspace() or c in '.!?')
        print(f"After symbols filter (English): {text}")
    text = text.strip()
    if len(text) == 0:
        print("Empty text, returning empty string")
        return ""
    if text[-1] not in '.!?':
        text += '.'
    print(f"Final normalized text: {text}")
    return text

def remove_duplicated_punctuations(text):
    text = re.sub(r"[.?!]+\?", "?", text)
    text = re.sub(r"[.?!]+!", "!", text)
    text = re.sub(r"[.?!]+\.", ".", text)
    return text

def alphabet_text(text):
    text = re.sub(r"(a|A)", "에이", text)
    text = re.sub(r"(b|B)", "비", text)
    text = re.sub(r"(c|C)", "씨", text)
    text = re.sub(r"(d|D)", "디", text)
    text = re.sub(r"(e|E)", "이", text)
    text = re.sub(r"(f|F)", "에프", text)
    text = re.sub(r"(g|G)", "쥐", text)
    text = re.sub(r"(h|H)", "에이치", text)
    text = re.sub(r"(i|I)", "아이", text)
    text = re.sub(r"(j|J)", "제이", text)
    text = re.sub(r"(k|K)", "케이", text)
    text = re.sub(r"(l|L)", "엘", text)
    text = re.sub(r"(m|M)", "엠", text)
    text = re.sub(r"(n|N)", "엔", text)
    text = re.sub(r"(o|O)", "오", text)
    text = re.sub(r"(p|P)", "피", text)
    text = re.sub(r"(q|Q)", "큐", text)
    text = re.sub(r"(r|R)", "알", text)
    text = re.sub(r"(s|S)", "에스", text)
    text = re.sub(r"(t|T)", "티", text)
    text = re.sub(r"(u|U)", "유", text)
    text = re.sub(r"(v|V)", "브이", text)
    text = re.sub(r"(w|W)", "더블유", text)
    text = re.sub(r"(x|X)", "엑스", text)
    text = re.sub(r"(y|Y)", "와이", text)
    text = re.sub(r"(z|Z)", "지", text)
    return text

def jamo_text(text):
    text = re.sub(r"ㄱ", "기역", text)
    text = re.sub(r"ㄴ", "니은", text)
    text = re.sub(r"ㄷ", "디귿", text)
    text = re.sub(r"ㄹ", "리을", text)
    text = re.sub(r"ㅁ", "미음", text)
    text = re.sub(r"ㅂ", "비읍", text)
    text = re.sub(r"ㅅ", "시옷", text)
    text = re.sub(r"ㅇ", "이응", text)
    text = re.sub(r"ㅈ", "지읒", text)
    text = re.sub(r"ㅊ", "치읓", text)
    text = re.sub(r"ㅋ", "키읔", text)
    text = re.sub(r"ㅌ", "티읕", text)
    text = re.sub(r"ㅍ", "피읖", text)
    text = re.sub(r"ㅎ", "히읗", text)
    text = re.sub(r"ㄲ", "쌍기역", text)
    text = re.sub(r"ㄸ", "쌍디귿", text)
    text = re.sub(r"ㅃ", "쌍비읍", text)
    text = re.sub(r"ㅆ", "쌍시옷", text)
    text = re.sub(r"ㅉ", "쌍지읒", text)
    text = re.sub(r"ㄳ", "기역시옷", text)
    text = re.sub(r"ㄵ", "니은지읒", text)
    text = re.sub(r"ㄶ", "니은히읗", text)
    text = re.sub(r"ㄺ", "리을기역", text)
    text = re.sub(r"ㄻ", "리을미음", text)
    text = re.sub(r"ㄼ", "리을비읍", text)
    text = re.sub(r"ㄽ", "리을시옷", text)
    text = re.sub(r"ㄾ", "리을티읕", text)
    text = re.sub(r"ㄿ", "리을피읍", text)
    text = re.sub(r"ㅀ", "리을히읗", text)
    text = re.sub(r"ㅄ", "비읍시옷", text)
    text = re.sub(r"ㅏ", "아", text)
    text = re.sub(r"ㅑ", "야", text)
    text = re.sub(r"ㅓ", "어", text)
    text = re.sub(r"ㅕ", "여", text)
    text = re.sub(r"ㅗ", "오", text)
    text = re.sub(r"ㅛ", "요", text)
    text = re.sub(r"ㅜ", "우", text)
    text = re.sub(r"ㅠ", "유", text)
    text = re.sub(r"ㅡ", "으", text)
    text = re.sub(r"ㅣ", "이", text)
    text = re.sub(r"ㅐ", "애", text)
    text = re.sub(r"ㅒ", "얘", text)
    text = re.sub(r"ㅔ", "에", text)
    text = re.sub(r"ㅖ", "예", text)
    text = re.sub(r"ㅘ", "와", text)
    text = re.sub(r"ㅙ", "왜", text)
    text = re.sub(r"ㅚ", "외", text)
    text = re.sub(r"ㅝ", "워", text)
    text = re.sub(r"ㅞ", "웨", text)
    text = re.sub(r"ㅟ", "위", text)
    text = re.sub(r"ㅢ", "의", text)
    return text

def convert_audio(input_path, output_path, sample_rate=16000):
    print(f"Converting {input_path} to {output_path} (16kHz, mono)...")
    cmd = ["ffmpeg", "-y", "-i", input_path, "-ar", str(sample_rate), "-ac", "1", output_path]
    try:
        subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        print(f"Conversion complete: {output_path}")
    except subprocess.CalledProcessError as e:
        print(f"FFmpeg error: {e.stderr.decode()}")
        sys.exit(1)

def speech_to_text(audio_file):
    print(f"Transcribing {audio_file} with Whisper...")
    result = whisper_model.transcribe(audio_file, language="ko")
    text = result['text'].strip()
    print(f"Recognized text: {text}")
    return text if text else ""

def translate_text(text):
    if not text:
        return ""
    try:
        result = translator(text)[0]['translation_text']
        print(f"Translated text: {result}")
        return result
    except Exception as e:
        print(f"Translation error: {e}")
        sys.exit(1)

def synthesize(text):
    global synthesizer
    print(f"Synthesizing text: {text}")
    wavs = synthesizer.tts(text, None, None)
    return wavs

if __name__ == "__main__":
    synthesizer = initialize_synthesizer()
    print(f"Extended symbols count: {len(extended_symbols)}")
    print(f"Sample korean chars: {korean_chars[:10]}")

    # WAV 파일 업로드
    input_audio = "/content/input_audio.wav"
    print("Please upload your Korean audio file as /content/input_audio.wav")
    from google.colab import files
    import os
    if not os.path.exists(input_audio):
        uploaded = files.upload()
        if not uploaded:
            print("No file uploaded, exiting")
            sys.exit(1)

    # 오디오 파일 포맷 변환 (16kHz, 모노)
    converted_audio = "/content/input_audio_converted.wav"
    convert_audio(input_audio, converted_audio)
    input_audio = converted_audio

    # STT: 한국어 음성을 텍스트로 변환
    korean_text = speech_to_text(input_audio)
    if not korean_text:
        print("No text recognized, exiting")
        sys.exit(1)
    korean_text = normalize_text(korean_text, is_korean=True)

    # 번역: 한국어 → 영어
    english_text = translate_text(korean_text)
    if not english_text:
        print("No translation, exiting")
        sys.exit(1)
    english_text = normalize_text(english_text, is_korean=False)

    # TTS: 영어 텍스트를 음성으로 합성
    wav = synthesize(english_text)
    output_file = "/content/output_english.wav"
    sf.write(output_file, wav, synthesizer.tts_config.audio["sample_rate"])
    print(f"English audio saved as {output_file}")
"""

with open("synthesize_text.py", "w") as f:
    f.write(code)

# 스크립트 실행
!/content/tts_env/bin/python synthesize_text.py

# 생성된 오디오 파일 확인 및 재생
!ls /content/*.wav
from IPython.display import Audio, display
import glob
for wav_file in glob.glob("/content/*.wav"):
    print(f"Playing: {wav_file}")
    display(Audio(wav_file))

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/TTS

# 필수 모듈 설치
!/content/tts_env/bin/pip install -q sentencepiece==0.2.0 transformers==4.46.3 soundfile==0.12.1 git+https://github.com/openai/whisper.git g2pK
!/content/tts_env/bin/pip install -q --force-reinstall sacremoses

# 모듈 설치 확인
!/content/tts_env/bin/pip list | grep -E "sentencepiece|transformers|soundfile|whisper|g2pK|sacremoses"

# Google Drive 마운트
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# 입력 WAV 파일 확인
!ls /content/*.wav

# config.json 백업 및 원본 문자셋 복원
import json
import shutil
config_path = "/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/config.json"
backup_path = config_path + ".backup"
if not shutil.os.path.exists(backup_path):
    shutil.copy(config_path, backup_path)
    print("Backed up config.json to", backup_path)

# 체크포인트와 맞는 문자셋으로 복원 (141 토큰)
with open(config_path, 'r') as f:
    config = json.load(f)
# 원본 문자셋 길이 141로 가정 (체크포인트 기준)
original_chars = config['characters']['characters']
if len(original_chars) != 141:
    print(f"Adjusting characters from {len(original_chars)} to 141")
    # 영어 알파벳 제거 (최근 추가된 부분)
    config['characters']['characters'] = original_chars.replace('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ', '')
    if len(config['characters']['characters']) > 141:
        config['characters']['characters'] = config['characters']['characters'][:141]
    elif len(config['characters']['characters']) < 141:
        print("Warning: Character set too small, may cause issues")
    with open(config_path, 'w') as f:
        json.dump(config, f, indent=4)
    print("Restored config.json characters to match checkpoint")

# synthesize_text.py 수정
code = """
import re
import sys
import numpy as np
from unicodedata import normalize
from TTS.utils.synthesizer import Synthesizer
import g2pk
from transformers import pipeline
import soundfile as sf
import whisper
import subprocess
import warnings
warnings.filterwarnings("ignore", category=FutureWarning)

# Colab 시스템 Python 경로 추가
sys.path.append('/usr/local/lib/python3.10/dist-packages')

# symbols 정의
from TTS.tts.utils.text.symbols import symbols

# 한글 문자 추가
korean_chars = [chr(i) for i in range(0xAC00, 0xD7A4)]  # Hangul Syllables
extended_symbols = symbols + korean_chars

# Synthesizer 초기화
def initialize_synthesizer():
    try:
        synthesizer = Synthesizer(
            tts_checkpoint="/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/best_model.pth.tar",
            tts_config_path="/content/drive/My Drive/Colab Notebooks/data/glowtts-v2/glowtts-v2-June-18-2025_06+37AM-3aa165a/config.json",
            tts_speakers_file=None,
            vocoder_checkpoint="/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/best_model_293026.pth.tar",
            vocoder_config="/content/drive/My Drive/Colab Notebooks/data/hifigan-v2/hifigan-v2-June-18-2025_03+27PM-3aa165a/config.json",
            encoder_checkpoint=None,
            encoder_config=None,
            use_cuda=False,
        )
        return synthesizer
    except Exception as e:
        print(f"Failed to initialize synthesizer: {e}")
        sys.exit(1)

# g2pK 초기화
g2p = g2pk.G2p()

# 번역 파이프라인 초기화
translator = pipeline("translation", model="Helsinki-NLP/opus-mt-ko-en")

# Whisper 모델 초기화
whisper_model = whisper.load_model("tiny")

def normalize_text(text, is_korean=True):
    print(f"Original text: {text}")
    text = text.strip()
    if is_korean:
        for c in ",;:":
            text = text.replace(c, ".")
        text = remove_duplicated_punctuations(text)
        print(f"After punctuation: {text}")
        text = jamo_text(text)
        print(f"After jamo: {text}")
        text = g2p.idioms(text)
        print(f"After idioms: {text}")
        text = g2pk.english.convert_eng(text, g2p.cmu)
        print(f"After english: {text}")
        text = g2pk.utils.annotate(text, g2p.mecab)
        print(f"After annotate: {text}")
        text = g2pk.numerals.convert_num(text)
        print(f"After numerals: {text}")
        text = re.sub("/[PJEB]", "", text)
        print(f"After regex: {text}")
        text = alphabet_text(text)
        print(f"After alphabet: {text}")
        text = "".join(c for c in text if (0xAC00 <= ord(c) <= 0xD7A3 or c.isspace() or c in '.!?' or c in symbols))
        print(f"After symbols filter: {text}")
        text = normalize("NFC", text)
    else:
        text = "".join(c for c in text if c.isalnum() or c.isspace() or c in '.!?')
        print(f"After symbols filter (English): {text}")
    text = text.strip()
    if len(text) == 0:
        print("Empty text, returning empty string")
        return ""
    if text[-1] not in '.!?':
        text += '.'
    print(f"Final normalized text: {text}")
    return text

def remove_duplicated_punctuations(text):
    text = re.sub(r"[.?!]+\?", "?", text)
    text = re.sub(r"[.?!]+!", "!", text)
    text = re.sub(r"[.?!]+\.", ".", text)
    return text

def alphabet_text(text):
    text = re.sub(r"(a|A)", "에이", text)
    text = re.sub(r"(b|B)", "비", text)
    text = re.sub(r"(c|C)", "씨", text)
    text = re.sub(r"(d|D)", "디", text)
    text = re.sub(r"(e|E)", "이", text)
    text = re.sub(r"(f|F)", "에프", text)
    text = re.sub(r"(g|G)", "쥐", text)
    text = re.sub(r"(h|H)", "에이치", text)
    text = re.sub(r"(i|I)", "아이", text)
    text = re.sub(r"(j|J)", "제이", text)
    text = re.sub(r"(k|K)", "케이", text)
    text = re.sub(r"(l|L)", "엘", text)
    text = re.sub(r"(m|M)", "엠", text)
    text = re.sub(r"(n|N)", "엔", text)
    text = re.sub(r"(o|O)", "오", text)
    text = re.sub(r"(p|P)", "피", text)
    text = re.sub(r"(q|Q)", "큐", text)
    text = re.sub(r"(r|R)", "알", text)
    text = re.sub(r"(s|S)", "에스", text)
    text = re.sub(r"(t|T)", "티", text)
    text = re.sub(r"(u|U)", "유", text)
    text = re.sub(r"(v|V)", "브이", text)
    text = re.sub(r"(w|W)", "더블유", text)
    text = re.sub(r"(x|X)", "엑스", text)
    text = re.sub(r"(y|Y)", "와이", text)
    text = re.sub(r"(z|Z)", "지", text)
    return text

def jamo_text(text):
    text = re.sub(r"ㄱ", "기역", text)
    text = re.sub(r"ㄴ", "니은", text)
    text = re.sub(r"ㄷ", "디귿", text)
    text = re.sub(r"ㄹ", "리을", text)
    text = re.sub(r"ㅁ", "미음", text)
    text = re.sub(r"ㅂ", "비읍", text)
    text = re.sub(r"ㅅ", "시옷", text)
    text = re.sub(r"ㅇ", "이응", text)
    text = re.sub(r"ㅈ", "지읒", text)
    text = re.sub(r"ㅊ", "치읓", text)
    text = re.sub(r"ㅋ", "키읔", text)
    text = re.sub(r"ㅌ", "티읕", text)
    text = re.sub(r"ㅍ", "피읖", text)
    text = re.sub(r"ㅎ", "히읗", text)
    text = re.sub(r"ㄲ", "쌍기역", text)
    text = re.sub(r"ㄸ", "쌍디귿", text)
    text = re.sub(r"ㅃ", "쌍비읍", text)
    text = re.sub(r"ㅆ", "쌍시옷", text)
    text = re.sub(r"ㅉ", "쌍지읒", text)
    text = re.sub(r"ㄳ", "기역시옷", text)
    text = re.sub(r"ㄵ", "니은지읒", text)
    text = re.sub(r"ㄶ", "니은히읗", text)
    text = re.sub(r"ㄺ", "리을기역", text)
    text = re.sub(r"ㄻ", "리을미음", text)
    text = re.sub(r"ㄼ", "리을비읍", text)
    text = re.sub(r"ㄽ", "리을시옷", text)
    text = re.sub(r"ㄾ", "리을티읕", text)
    text = re.sub(r"ㄿ", "리을피읍", text)
    text = re.sub(r"ㅀ", "리을히읗", text)
    text = re.sub(r"ㅄ", "비읍시옷", text)
    text = re.sub(r"ㅏ", "아", text)
    text = re.sub(r"ㅑ", "야", text)
    text = re.sub(r"ㅓ", "어", text)
    text = re.sub(r"ㅕ", "여", text)
    text = re.sub(r"ㅗ", "오", text)
    text = re.sub(r"ㅛ", "요", text)
    text = re.sub(r"ㅜ", "우", text)
    text = re.sub(r"ㅠ", "유", text)
    text = re.sub(r"ㅡ", "으", text)
    text = re.sub(r"ㅣ", "이", text)
    text = re.sub(r"ㅐ", "애", text)
    text = re.sub(r"ㅒ", "얘", text)
    text = re.sub(r"ㅔ", "에", text)
    text = re.sub(r"ㅖ", "예", text)
    text = re.sub(r"ㅘ", "와", text)
    text = re.sub(r"ㅙ", "왜", text)
    text = re.sub(r"ㅚ", "외", text)
    text = re.sub(r"ㅝ", "워", text)
    text = re.sub(r"ㅞ", "웨", text)
    text = re.sub(r"ㅟ", "위", text)
    text = re.sub(r"ㅢ", "의", text)
    return text

def convert_audio(input_path, output_path, sample_rate=16000):
    print(f"Converting {input_path} to {output_path} (16kHz, mono)...")
    cmd = ["ffmpeg", "-y", "-i", input_path, "-ar", str(sample_rate), "-ac", "1", output_path]
    try:
        subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        print(f"Conversion complete: {output_path}")
    except subprocess.CalledProcessError as e:
        print(f"FFmpeg error: {e.stderr.decode()}")
        sys.exit(1)

def speech_to_text(audio_file):
    print(f"Transcribing {audio_file} with Whisper...")
    try:
        result = whisper_model.transcribe(audio_file, language="ko")
        text = result['text'].strip()
        print(f"Recognized text: {text}")
        return text
    except Exception as e:
        print(f"Whisper error: {e}")
        return ""

def translate_text(text):
    if not text:
        return ""
    try:
        result = translator(text)[0]['translation_text']
        print(f"Translated text: {result}")
        return result
    except Exception as e:
        print(f"Translation error: {e}")
        sys.exit(1)

def synthesize(text):
    global synthesizer
    print(f"Synthesizing text: {text}")
    try:
        wavs = synthesizer.tts(text, None, None)
        return wavs
    except Exception as e:
        print(f"Synthesis error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    synthesizer = initialize_synthesizer()
    print(f"Extended symbols count: {len(extended_symbols)}")
    print(f"Sample korean chars: {korean_chars[:10]}")

    # WAV 파일 업로드
    input_audio = "/content/input_audio.wav"
    print("Please upload your Korean audio file as /content/input_audio.wav")
    try:
        from google.colab import files
    except ImportError:
        print("Not running in Colab, skipping file upload")
        files = None
    import os
    if not os.path.exists(input_audio) and files:
        uploaded = files.upload()
        if not uploaded:
            print("No file uploaded, exiting")
            sys.exit(1)
    elif not os.path.exists(input_audio):
        print(f"Input file {input_audio} not found, exiting")
        sys.exit(1)

    # 오디오 파일 포맷 변환 (16kHz, 모노)
    converted_audio = "/content/input_audio_converted.wav"
    convert_audio(input_audio, converted_audio)
    input_audio = converted_audio

    # STT: 한국어 음성을 텍스트로 변환
    korean_text = speech_to_text(input_audio)
    if not korean_text:
        print("No text recognized, exiting")
        sys.exit(1)
    korean_text = normalize_text(korean_text, is_korean=True)

    # 번역: 한국어 → 영어
    english_text = translate_text(korean_text)
    if not english_text:
        print("No translation, exiting")
        sys.exit(1)
    english_text = normalize_text(english_text, is_korean=False)

    # TTS: 영어 텍스트를 음성으로 합성
    wav = synthesize(english_text)
    output_file = "/content/output_english.wav"
    sf.write(output_file, wav, synthesizer.tts_config.audio["sample_rate"])
    print(f"English audio saved as {output_file}")
"""

with open("synthesize_text.py", "w") as f:
    f.write(code)

# 스크립트 실행
!/content/tts_env/bin/python synthesize_text.py

# 생성된 오디오 파일 확인 및 재생
!ls /content/*.wav
from IPython.display import Audio, display
import glob
for wav_file in glob.glob("/content/*.wav"):
    print(f"Playing: {wav_file}")
    display(Audio(wav_file))